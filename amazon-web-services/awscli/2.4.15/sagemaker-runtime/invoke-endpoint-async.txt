INVOKE-ENDPOINT-ASYNC()                                INVOKE-ENDPOINT-ASYNC()



NAME
       invoke-endpoint-async -

DESCRIPTION
       After you deploy a model into production using Amazon SageMaker hosting
       services, your client applications use this API to get inferences  from
       the model hosted at the specified endpoint in an asynchronous manner.

       Inference  requests sent to this API are enqueued for asynchronous pro-
       cessing. The processing of the inference request may or  may  not  com-
       plete  before  the  you  receive a response from this API. The response
       from this API will not contain the result of the inference request  but
       contain information about where you can locate it.

       Amazon  SageMaker strips all POST headers except those supported by the
       API. Amazon SageMaker might add additional headers. You should not rely
       on the behavior of headers outside those enumerated in the request syn-
       tax.

       Calls to InvokeEndpointAsync are authenticated by using Amazon Web Ser-
       vices Signature Version 4. For information, see Authenticating Requests
       (Amazon Web Services Signature Version 4) in the Amazon S3  API  Refer-
       ence .

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            invoke-endpoint-async
          --endpoint-name <value>
          [--content-type <value>]
          [--accept <value>]
          [--custom-attributes <value>]
          [--inference-id <value>]
          --input-location <value>
          [--request-ttl-seconds <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --endpoint-name (string)
          The  name  of  the  endpoint that you specified when you created the
          endpoint         using         the         `          CreateEndpoint
          https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpoint.html`__
          API.

       --content-type (string)
          The MIME type of the input data in the request body.

       --accept (string)
          The desired MIME type of the inference in the response.

       --custom-attributes (string)
          Provides additional information about a  request  for  an  inference
          submitted  to  a  model  hosted at an Amazon SageMaker endpoint. The
          information is an opaque value that is forwarded verbatim. You could
          use  this  value,  for example, to provide an ID that you can use to
          track a request or to provide other metadata that a service endpoint
          was  programmed  to  process. The value must consist of no more than
          1024 visible US-ASCII characters  as  specified  in  Section  3.3.6.
          Field   Value   Components   of   the  Hypertext  Transfer  Protocol
          (HTTP/1.1).

          The code in your model is responsible for setting  or  updating  any
          custom  attributes  in  the response. If your code does not set this
          value in the response, an empty value is returned. For example, if a
          custom attribute represents the trace ID, your model can prepend the
          custom attribute with Trace ID : in your post-processing function.

          This feature is currently supported in the Amazon Web Services  SDKs
          but not in the Amazon SageMaker Python SDK.

       --inference-id (string)
          The identifier for the inference request. Amazon SageMaker will gen-
          erate an identifier for you if none is specified.

       --input-location (string)
          The Amazon S3 URI where the inference request payload is stored.

       --request-ttl-seconds (integer)
          Maximum age in seconds a request can be in the queue  before  it  is
          marked as expired.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       InferenceId -> (string)
          Identifier  for  an  inference request. This will be the same as the
          InferenceId specified in the input. Amazon SageMaker  will  generate
          an identifier for you if you do not specify one.

       OutputLocation -> (string)
          The Amazon S3 URI where the inference response payload is stored.



                                                       INVOKE-ENDPOINT-ASYNC()

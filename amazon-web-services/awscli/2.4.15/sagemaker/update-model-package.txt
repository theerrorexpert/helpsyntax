UPDATE-MODEL-PACKAGE()                                  UPDATE-MODEL-PACKAGE()



NAME
       update-model-package -

DESCRIPTION
       Updates a versioned model.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            update-model-package
          --model-package-arn <value>
          [--model-approval-status <value>]
          [--approval-description <value>]
          [--customer-metadata-properties <value>]
          [--customer-metadata-properties-to-remove <value>]
          [--additional-inference-specifications-to-add <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --model-package-arn (string)
          The Amazon Resource Name (ARN) of the model package.

       --model-approval-status (string)
          The approval status of the model.

          Possible values:

          o Approved

          o Rejected

          o PendingManualApproval

       --approval-description (string)
          A description for the approval status of the model.

       --customer-metadata-properties (map)
          The  metadata properties associated with the model package versions.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --customer-metadata-properties-to-remove (list)
          The metadata properties associated with the model  package  versions
          to remove.

          (string)

       Syntax:

          "string" "string" ...

       --additional-inference-specifications-to-add (list)
          An  array  of additional Inference Specification objects to be added
          to the existing array additional Inference Specification. Total num-
          ber  of  additional Inference Specifications can not exceed 15. Each
          additional Inference Specification specifies artifacts based on this
          model  package  that  can  be used on inference endpoints. Generally
          used with SageMaker Neo to store the compiled artifacts.

          (structure)
              A structure of additional  Inference  Specification.  Additional
              Inference  Specification  specifies details about inference jobs
              that can be run with models based on this model package

              Name -> (string)
                 A unique name to identify the additional inference specifica-
                 tion.  The  name must be unique within the list of your addi-
                 tional inference specifications for a particular model  pack-
                 age.

              Description -> (string)
                 A description of the additional Inference specification

              Containers -> (list)
                 The  Amazon  ECR  registry path of the Docker image that con-
                 tains the inference code.

                 (structure)
                     Describes the Docker container for the model package.

                     ContainerHostname -> (string)
                        The DNS host name for the Docker container.

                     Image -> (string)
                        The Amazon EC2 Container Registry  (Amazon  ECR)  path
                        where inference code is stored.

                        If  you are using your own custom algorithm instead of
                        an algorithm provided by Amazon SageMaker, the  infer-
                        ence  code  must  meet  Amazon SageMaker requirements.
                        Amazon  SageMaker   supports   both   registry/reposi-
                        tory[:tag] and registry/repository[@digest] image path
                        formats. For more  information,  see  Using  Your  Own
                        Algorithms with Amazon SageMaker .

                     ImageDigest -> (string)
                        An  MD5 hash of the training algorithm that identifies
                        the Docker image used for training.

                     ModelDataUrl -> (string)
                        The Amazon S3 path where the  model  artifacts,  which
                        result from model training, are stored. This path must
                        point to a single gzip compressed tar archive (.tar.gz
                        suffix).

                        NOTE:
                            The  model  artifacts must be in an S3 bucket that
                            is in the same region as the model package.

                     ProductId -> (string)
                        The Amazon Web Services Marketplace product ID of  the
                        model package.

                     Environment -> (map)
                        The  environment  variables  to set in the Docker con-
                        tainer. Each key and value in the  Environment  string
                        to  string  map can have length of up to 1024. We sup-
                        port up to 16 entries in the map.

                        key -> (string)

                        value -> (string)

                     ModelInput -> (structure)
                        A structure with Model Input details.

                        DataInputConfig -> (string)
                            The input configuration object for the model.

                     Framework -> (string)
                        The machine learning framework of  the  model  package
                        container image.

                     FrameworkVersion -> (string)
                        The  framework  version of the Model Package Container
                        Image.

                     NearestModelName -> (string)
                        The name of a pre-trained machine learning benchmarked
                        by  Amazon  SageMaker Inference Recommender model that
                        matches your model. You can find a list of benchmarked
                        models by calling ListModelMetadata .

              SupportedTransformInstanceTypes -> (list)
                 A  list  of  the instance types on which a transformation job
                 can be run or on which an endpoint can be deployed.

                 (string)

              SupportedRealtimeInferenceInstanceTypes -> (list)
                 A list of the instance types that are used to generate infer-
                 ences in real-time.

                 (string)

              SupportedContentTypes -> (list)
                 The supported MIME types for the input data.

                 (string)

              SupportedResponseMIMETypes -> (list)
                 The supported MIME types for the output data.

                 (string)

       JSON Syntax:

          [
            {
              "Name": "string",
              "Description": "string",
              "Containers": [
                {
                  "ContainerHostname": "string",
                  "Image": "string",
                  "ImageDigest": "string",
                  "ModelDataUrl": "string",
                  "ProductId": "string",
                  "Environment": {"string": "string"
                    ...},
                  "ModelInput": {
                    "DataInputConfig": "string"
                  },
                  "Framework": "string",
                  "FrameworkVersion": "string",
                  "NearestModelName": "string"
                }
                ...
              ],
              "SupportedTransformInstanceTypes": ["ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge", ...],
              "SupportedRealtimeInferenceInstanceTypes": ["ml.t2.medium"|"ml.t2.large"|"ml.t2.xlarge"|"ml.t2.2xlarge"|"ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.m5d.large"|"ml.m5d.xlarge"|"ml.m5d.2xlarge"|"ml.m5d.4xlarge"|"ml.m5d.12xlarge"|"ml.m5d.24xlarge"|"ml.c4.large"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.large"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.c5d.large"|"ml.c5d.xlarge"|"ml.c5d.2xlarge"|"ml.c5d.4xlarge"|"ml.c5d.9xlarge"|"ml.c5d.18xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge"|"ml.r5.large"|"ml.r5.xlarge"|"ml.r5.2xlarge"|"ml.r5.4xlarge"|"ml.r5.12xlarge"|"ml.r5.24xlarge"|"ml.r5d.large"|"ml.r5d.xlarge"|"ml.r5d.2xlarge"|"ml.r5d.4xlarge"|"ml.r5d.12xlarge"|"ml.r5d.24xlarge"|"ml.inf1.xlarge"|"ml.inf1.2xlarge"|"ml.inf1.6xlarge"|"ml.inf1.24xlarge", ...],
              "SupportedContentTypes": ["string", ...],
              "SupportedResponseMIMETypes": ["string", ...]
            }
            ...
          ]

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       ModelPackageArn -> (string)
          The Amazon Resource Name (ARN) of the model.



                                                        UPDATE-MODEL-PACKAGE()

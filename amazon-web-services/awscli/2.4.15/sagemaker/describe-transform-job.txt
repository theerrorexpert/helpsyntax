DESCRIBE-TRANSFORM-JOB()                              DESCRIBE-TRANSFORM-JOB()



NAME
       describe-transform-job -

DESCRIPTION
       Returns information about a transform job.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            describe-transform-job
          --transform-job-name <value>
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --transform-job-name (string)
          The name of the transform job that you want to view details of.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       TransformJobName -> (string)
          The name of the transform job.

       TransformJobArn -> (string)
          The Amazon Resource Name (ARN) of the transform job.

       TransformJobStatus -> (string)
          The  status  of  the transform job. If the transform job failed, the
          reason is returned in the FailureReason field.

       FailureReason -> (string)
          If the transform job failed, FailureReason describes why it  failed.
          A  transform  job creates a log file, which includes error messages,
          and stores it as an Amazon S3 object. For more information, see  Log
          Amazon SageMaker Events with Amazon CloudWatch .

       ModelName -> (string)
          The name of the model used in the transform job.

       MaxConcurrentTransforms -> (integer)
          The  maximum  number of parallel requests on each instance node that
          can be launched in a transform job. The default value is 1.

       ModelClientConfig -> (structure)
          The timeout and maximum number of retries for processing a transform
          job invocation.

          InvocationsTimeoutInSeconds -> (integer)
              The timeout value in seconds for an invocation request.

          InvocationsMaxRetries -> (integer)
              The maximum number of retries when invocation requests are fail-
              ing.

       MaxPayloadInMB -> (integer)
          The maximum payload size, in MB, used in the transform job.

       BatchStrategy -> (string)
          Specifies the number of records to include in a  mini-batch  for  an
          HTTP  inference  request.  A  record  is a single unit of input data
          that inference can be made on. For example, a single line in  a  CSV
          file is a record.

          To  enable  the  batch  strategy,  you  must set SplitType to Line ,
          RecordIO , or TFRecord .

       Environment -> (map)
          The environment variables to set in the Docker container. We support
          up to 16 key and values entries in the map.

          key -> (string)

          value -> (string)

       TransformInput -> (structure)
          Describes  the  dataset to be transformed and the Amazon S3 location
          where it is stored.

          DataSource -> (structure)
              Describes the location of the channel data,  which  is,  the  S3
              location of the input data that the model can consume.

              S3DataSource -> (structure)
                 The  S3 location of the data source that is associated with a
                 channel.

                 S3DataType -> (string)
                     If you choose S3Prefix , S3Uri identifies a key name pre-
                     fix. Amazon SageMaker uses all objects with the specified
                     key name prefix for batch transform.

                     If you choose ManifestFile , S3Uri identifies  an  object
                     that  is a manifest file containing a list of object keys
                     that you want Amazon SageMaker to use  for  batch  trans-
                     form.

                     The  following  values  are  compatible:  ManifestFile  ,
                     S3Prefix

                     The following value is not compatible: AugmentedManifest-
                     File

                 S3Uri -> (string)
                     Depending  on  the  value  specified for the S3DataType ,
                     identifies either a key name prefix or  a  manifest.  For
                     example:

                     o A  key  name  prefix might look like this: s3://bucket-
                       name/exampleprefix .

                     o A manifest might look like this:  s3://bucketname/exam-
                       ple.manifest    The manifest is an S3 object which is a
                       JSON file with the  following  format:    [  {"prefix":
                       "s3://customer_bucket/some/prefix/"},            "rela-
                       tive/path/to/custdata-1",          "relative/path/cust-
                       data-2",      ...      "relative/path/custdata-N"     ]
                       The preceding  JSON  matches  the  following  S3Uris  :
                       s3://customer_bucket/some/prefix/relative/path/to/cust-
                       data-1           s3://customer_bucket/some/prefix/rela-
                       tive/path/custdata-2            ...           s3://cus-
                       tomer_bucket/some/prefix/relative/path/custdata-N   The
                       complete set of S3Uris in this manifest constitutes the
                       input data for the channel  for  this  datasource.  The
                       object  that  each S3Uris points to must be readable by
                       the IAM role that  Amazon  SageMaker  uses  to  perform
                       tasks on your behalf.

          ContentType -> (string)
              The  multipurpose  internet  mail  extension  (MIME) type of the
              data. Amazon SageMaker uses the MIME type with each http call to
              transfer data to the transform job.

          CompressionType -> (string)
              If  your  transform  data is compressed, specify the compression
              type. Amazon SageMaker automatically decompresses the  data  for
              the transform job accordingly. The default value is None .

          SplitType -> (string)
              The  method  to use to split the transform job's data files into
              smaller batches. Splitting is necessary when the total  size  of
              each  object  is  too  large to fit in a single request. You can
              also use data splitting to  improve  performance  by  processing
              multiple  concurrent  mini-batches. The default value for Split-
              Type is None , which indicates that input  data  files  are  not
              split,  and  request  payloads contain the entire contents of an
              input object. Set the value of this parameter to Line  to  split
              records on a newline character boundary. SplitType also supports
              a number of record-oriented binary data formats. Currently,  the
              supported record formats are:

              o RecordIO

              o TFRecord

              When  splitting  is enabled, the size of a mini-batch depends on
              the values of the BatchStrategy and  MaxPayloadInMB  parameters.
              When  the  value  of BatchStrategy is MultiRecord , Amazon Sage-
              Maker sends the maximum number of records in each request, up to
              the  MaxPayloadInMB limit. If the value of BatchStrategy is Sin-
              gleRecord , Amazon SageMaker sends individual  records  in  each
              request.

              NOTE:
                 Some  data  formats  represent  a  record as a binary payload
                 wrapped with extra padding bytes. When splitting  is  applied
                 to  a  binary data format, padding is removed if the value of
                 BatchStrategy is set to SingleRecord . Padding is not removed
                 if the value of BatchStrategy is set to MultiRecord .

                 For  more  information  about RecordIO , see Create a Dataset
                 Using RecordIO in the MXNet documentation. For more  informa-
                 tion about TFRecord , see Consuming TFRecord data in the Ten-
                 sorFlow documentation.

       TransformOutput -> (structure)
          Identifies the Amazon S3 location where you want Amazon SageMaker to
          save the results from the transform job.

          S3OutputPath -> (string)
              The  Amazon S3 path where you want Amazon SageMaker to store the
              results    of    the     transform     job.     For     example,
              s3://bucket-name/key-name-prefix .

              For  every  S3 object used as input for the transform job, batch
              transform stores the transformed data with an .``out`` suffix in
              a  corresponding subfolder in the location in the output prefix.
              For    example,    for    the    input    data     stored     at
              s3://bucket-name/input-name-prefix/dataset01/data.csv   ,  batch
              transform stores the transformed data  at  s3://bucket-name/out-
              put-name-prefix/input-name-prefix/data.csv.out . Batch transform
              doesn't upload partially processed  objects.  For  an  input  S3
              object  that  contains  multiple records, it creates an .``out``
              file only if the transform job succeeds on the entire file. When
              the  input contains multiple S3 objects, the batch transform job
              processes the listed S3 objects and uploads only the output  for
              successfully  processed  objects.  If  any  object  fails in the
              transform job batch transform marks the job as failed to  prompt
              investigation.

          Accept -> (string)
              The  MIME type used to specify the output data. Amazon SageMaker
              uses the MIME type with each http call to transfer data from the
              transform job.

          AssembleWith -> (string)
              Defines  how  to  assemble the results of the transform job as a
              single S3 object. Choose a format that  is  most  convenient  to
              you. To concatenate the results in binary format, specify None .
              To add a newline character  at  the  end  of  every  transformed
              record, specify Line .

          KmsKeyId -> (string)
              The  Amazon Web Services Key Management Service (Amazon Web Ser-
              vices KMS) key that Amazon SageMaker uses to encrypt  the  model
              artifacts  at  rest  using Amazon S3 server-side encryption. The
              KmsKeyId can be any of the following formats:

              o Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab

              o Key                                                       ARN:
                arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab

              o Alias name: alias/ExampleAlias

              o Alias name ARN: arn:aws:kms:us-west-2:111122223333:alias/Exam-
                pleAlias

              If  you  don't  provide  a KMS key ID, Amazon SageMaker uses the
              default KMS key for Amazon S3 for your role's account. For  more
              information,  see KMS-Managed Encryption Keys in the Amazon Sim-
              ple Storage Service Developer Guide.

              The KMS key policy must grant permission to the  IAM  role  that
              you  specify in your  CreateModel request. For more information,
              see Using Key Policies in Amazon Web Services KMS in the  Amazon
              Web Services Key Management Service Developer Guide .

       TransformResources -> (structure)
          Describes the resources, including ML instance types and ML instance
          count, to use for the transform job.

          InstanceType -> (string)
              The ML compute instance type for the transform job. If  you  are
              using   built-in   algorithms   to  transform  moderately  sized
              datasets,  we  recommend  using  ml.m4.xlarge   or   ml.m5.large
              instance types.

          InstanceCount -> (integer)
              The  number of ML compute instances to use in the transform job.
              For distributed transform jobs, specify a value greater than  1.
              The default value is 1 .

          VolumeKmsKeyId -> (string)
              The  Amazon Web Services Key Management Service (Amazon Web Ser-
              vices KMS) key that Amazon SageMaker uses to encrypt model  data
              on  the  storage  volume  attached to the ML compute instance(s)
              that run the batch transform job.

              NOTE:
                 Certain Nitro-based instances include local  storage,  depen-
                 dent   on  the  instance  type.  Local  storage  volumes  are
                 encrypted using a hardware module on the instance. You  can't
                 request  a  VolumeKmsKeyId  when  using an instance type with
                 local storage.

                 For a list of instance  types  that  support  local  instance
                 storage, see Instance Store Volumes .

                 For more information about local instance storage encryption,
                 see SSD Instance Store Volumes .

              The VolumeKmsKeyId can be any of the following formats:

              o Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab

              o Key                                                       ARN:
                arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab

              o Alias name: alias/ExampleAlias

              o Alias name ARN: arn:aws:kms:us-west-2:111122223333:alias/Exam-
                pleAlias

       CreationTime -> (timestamp)
          A timestamp that shows when the transform Job was created.

       TransformStartTime -> (timestamp)
          Indicates  when  the  transform  job starts on ML instances. You are
          billed for the time interval between this  time  and  the  value  of
          TransformEndTime .

       TransformEndTime -> (timestamp)
          Indicates  when the transform job has been completed, or has stopped
          or failed. You are billed for the time interval  between  this  time
          and the value of TransformStartTime .

       LabelingJobArn -> (string)
          The  Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth
          labeling job that created the transform or training job.

       AutoMLJobArn -> (string)
          The Amazon Resource Name (ARN) of the AutoML transform job.

       DataProcessing -> (structure)
          The data structure used to specify the data to be used for inference
          in  a batch transform job and to associate the data that is relevant
          to the prediction results in the output. The input  filter  provided
          allows you to exclude input data that is not needed for inference in
          a batch transform job. The output  filter  provided  allows  you  to
          include  input  data relevant to interpreting the predictions in the
          output from the job. For more information, see Associate  Prediction
          Results with their Corresponding Input Records .

          InputFilter -> (string)
              A JSONPath expression used to select a portion of the input data
              to pass to the  algorithm.  Use  the  InputFilter  parameter  to
              exclude  fields,  such  as  an ID column, from the input. If you
              want Amazon SageMaker to pass the entire input  dataset  to  the
              algorithm, accept the default value $ .

              Examples: "$" , "$[1:]" , "$.features"

          OutputFilter -> (string)
              A  JSONPath  expression  used  to select a portion of the joined
              dataset to save in the output file for a batch transform job. If
              you  want  Amazon SageMaker to store the entire input dataset in
              the output file, leave the default value, $  .  If  you  specify
              indexes  that  aren't  within  the  dimension size of the joined
              dataset, you get an error.

              Examples: "$" , "$[0,5:]" , "$['id','SageMakerOutput']"

          JoinSource -> (string)
              Specifies the source of the data to join  with  the  transformed
              data. The valid values are None and Input . The default value is
              None , which specifies not to join the  input  with  the  trans-
              formed  data.  If  you  want the batch transform job to join the
              original input data with the transformed data, set JoinSource to
              Input  . You can specify OutputFilter as an additional filter to
              select a portion of the joined dataset and store it in the  out-
              put file.

              For  JSON  or JSONLines objects, such as a JSON array, SageMaker
              adds the transformed  data  to  the  input  JSON  object  in  an
              attribute  called  SageMakerOutput  . The joined result for JSON
              must be a key-value pair object. If the input is not a key-value
              pair  object, SageMaker creates a new JSON file. In the new JSON
              file, and the input data is stored under the SageMakerInput  key
              and the results are stored in SageMakerOutput .

              For CSV data, SageMaker takes each row as a JSON array and joins
              the transformed data with the input  by  appending  each  trans-
              formed  row  to  the  end  of the input. The joined data has the
              original input data followed by the  transformed  data  and  the
              output is a CSV file.

              For  information  on  how  joining  in applied, see Workflow for
              Associating Inferences with Input Records .

       ExperimentConfig -> (structure)
          Associates a SageMaker job as a trial component with  an  experiment
          and trial. Specified when you call the following APIs:

          o CreateProcessingJob

          o CreateTrainingJob

          o CreateTransformJob

          ExperimentName -> (string)
              The name of an existing experiment to associate the trial compo-
              nent with.

          TrialName -> (string)
              The name of an existing trial to associate the  trial  component
              with. If not specified, a new trial is created.

          TrialComponentDisplayName -> (string)
              The  display  name  for  the  trial component. If this key isn't
              specified, the display name is the trial component name.



                                                      DESCRIBE-TRANSFORM-JOB()

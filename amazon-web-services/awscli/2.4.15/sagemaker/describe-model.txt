DESCRIBE-MODEL()                                              DESCRIBE-MODEL()



NAME
       describe-model -

DESCRIPTION
       Describes a model that you created using the CreateModel API.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            describe-model
          --model-name <value>
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --model-name (string)
          The name of the model.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       ModelName -> (string)
          Name of the Amazon SageMaker model.

       PrimaryContainer -> (structure)
          The  location  of  the primary inference code, associated artifacts,
          and custom environment map that the inference code uses when  it  is
          deployed in production.

          ContainerHostname -> (string)
              This  parameter is ignored for models that contain only a Prima-
              ryContainer .

              When a ContainerDefinition is part of an inference pipeline, the
              value of the parameter uniquely identifies the container for the
              purposes of logging and metrics. For information, see  Use  Logs
              and  Metrics  to  Monitor  an  Inference Pipeline . If you don't
              specify a value for this  parameter  for  a  ContainerDefinition
              that is part of an inference pipeline, a unique name is automat-
              ically assigned based on the position of the ContainerDefinition
              in  the  pipeline. If you specify a value for the ContainerHost-
              Name for any ContainerDefinition that is part  of  an  inference
              pipeline,  you  must  specify  a value for the ContainerHostName
              parameter of every ContainerDefinition in that pipeline.

          Image -> (string)
              The path where inference code is stored. This can be  either  in
              Amazon  EC2  Container  Registry or in a Docker registry that is
              accessible from the same VPC that you configure  for  your  end-
              point.  If you are using your own custom algorithm instead of an
              algorithm provided by Amazon SageMaker, the inference code  must
              meet  Amazon  SageMaker  requirements. Amazon SageMaker supports
              both registry/repository[:tag] and  registry/repository[@digest]
              image  path  formats.  For  more information, see Using Your Own
              Algorithms with Amazon SageMaker

          ImageConfig -> (structure)
              Specifies whether the model container is in Amazon ECR or a pri-
              vate Docker registry accessible from your Amazon Virtual Private
              Cloud (VPC). For information about storing containers in a  pri-
              vate  Docker  registry,  see  Use  a Private Docker Registry for
              Real-Time Inference Containers

              RepositoryAccessMode -> (string)
                 Set this to one of the following values:

                 o Platform - The model image is hosted in Amazon ECR.

                 o Vpc - The model image is hosted in a  private  Docker  reg-
                   istry in your VPC.

              RepositoryAuthConfig -> (structure)
                 (Optional)  Specifies an authentication configuration for the
                 private docker registry where your  model  image  is  hosted.
                 Specify  a  value for this property only if you specified Vpc
                 as the value for the RepositoryAccessMode field, and the pri-
                 vate Docker registry where the model image is hosted requires
                 authentication.

                 RepositoryCredentialsProviderArn -> (string)
                     The Amazon Resource Name (ARN) of an Amazon Web  Services
                     Lambda function that provides credentials to authenticate
                     to the private Docker registry where your model image  is
                     hosted. For information about how to create an Amazon Web
                     Services Lambda function, see Create  a  Lambda  function
                     with the console in the Amazon Web Services Lambda Devel-
                     oper Guide .

          Mode -> (string)
              Whether the container hosts a single model or multiple models.

          ModelDataUrl -> (string)
              The S3 path where the model artifacts, which result  from  model
              training, are stored. This path must point to a single gzip com-
              pressed tar archive (.tar.gz suffix). The S3  path  is  required
              for  Amazon  SageMaker  built-in  algorithms, but not if you use
              your own algorithms. For  more  information  on  built-in  algo-
              rithms, see Common Parameters .

              NOTE:
                 The  model  artifacts  must be in an S3 bucket that is in the
                 same region as the model or endpoint you are creating.

              If you provide a value for this parameter, Amazon SageMaker uses
              Amazon  Web  Services  Security  Token Service to download model
              artifacts from the S3 path you provide. Amazon Web Services  STS
              is  activated in your IAM user account by default. If you previ-
              ously deactivated Amazon Web Services STS for a region, you need
              to  reactivate Amazon Web Services STS for that region. For more
              information, see Activating and Deactivating Amazon Web Services
              STS  in an Amazon Web Services Region in the Amazon Web Services
              Identity and Access Management User Guide .

              WARNING:
                 If you use a built-in algorithm to  create  a  model,  Amazon
                 SageMaker  requires  that  you provide a S3 path to the model
                 artifacts in ModelDataUrl .

          Environment -> (map)
              The environment variables to set in the Docker  container.  Each
              key  and  value in the Environment string to string map can have
              length of up to 1024. We support up to 16 entries in the map.

              key -> (string)

              value -> (string)

          ModelPackageName -> (string)
              The name or Amazon Resource Name (ARN) of the model  package  to
              use to create the model.

          InferenceSpecificationName -> (string)
              The inference specification name in the model package version.

          MultiModelConfig -> (structure)
              Specifies additional configuration for multi-model endpoints.

              ModelCacheSetting -> (string)
                 Whether  to  cache  models  for  a  multi-model  endpoint. By
                 default, multi-model endpoints cache models so that  a  model
                 does  not  have  to  be  loaded  into  memory each time it is
                 invoked. Some use cases do not benefit  from  model  caching.
                 For  example,  if  an endpoint hosts a large number of models
                 that are each invoked infrequently, the endpoint  might  per-
                 form  better  if  you disable model caching. To disable model
                 caching, set the value of this parameter to Disabled .

       Containers -> (list)
          The containers in the inference pipeline.

          (structure)
              Describes the container, as part of model definition.

              ContainerHostname -> (string)
                 This parameter is ignored for models that contain only a Pri-
                 maryContainer .

                 When  a ContainerDefinition is part of an inference pipeline,
                 the value of the parameter uniquely identifies the  container
                 for the purposes of logging and metrics. For information, see
                 Use Logs and Metrics to Monitor an Inference  Pipeline  .  If
                 you  don't  specify a value for this parameter for a Contain-
                 erDefinition that is part of an inference pipeline, a  unique
                 name  is  automatically assigned based on the position of the
                 ContainerDefinition in the pipeline. If you specify  a  value
                 for the ContainerHostName for any ContainerDefinition that is
                 part of an inference pipeline, you must specify a  value  for
                 the  ContainerHostName parameter of every ContainerDefinition
                 in that pipeline.

              Image -> (string)
                 The path where inference code is stored. This can  be  either
                 in Amazon EC2 Container Registry or in a Docker registry that
                 is accessible from the same VPC that you configure  for  your
                 endpoint.  If you are using your own custom algorithm instead
                 of an algorithm provided by Amazon SageMaker,  the  inference
                 code  must  meet  Amazon SageMaker requirements. Amazon Sage-
                 Maker  supports  both  registry/repository[:tag]   and   reg-
                 istry/repository[@digest] image path formats. For more infor-
                 mation, see Using Your Own Algorithms with Amazon SageMaker

              ImageConfig -> (structure)
                 Specifies whether the model container is in Amazon ECR  or  a
                 private  Docker  registry accessible from your Amazon Virtual
                 Private Cloud (VPC). For information about storing containers
                 in  a  private Docker registry, see Use a Private Docker Reg-
                 istry for Real-Time Inference Containers

                 RepositoryAccessMode -> (string)
                     Set this to one of the following values:

                     o Platform - The model image is hosted in Amazon ECR.

                     o Vpc - The model image is hosted  in  a  private  Docker
                       registry in your VPC.

                 RepositoryAuthConfig -> (structure)
                     (Optional)  Specifies an authentication configuration for
                     the private docker registry where  your  model  image  is
                     hosted.  Specify  a  value  for this property only if you
                     specified Vpc as the value for  the  RepositoryAccessMode
                     field,  and  the  private Docker registry where the model
                     image is hosted requires authentication.

                     RepositoryCredentialsProviderArn -> (string)
                        The Amazon Resource Name (ARN) of an Amazon  Web  Ser-
                        vices  Lambda  function  that  provides credentials to
                        authenticate to the private Docker registry where your
                        model  image  is  hosted. For information about how to
                        create an Amazon Web  Services  Lambda  function,  see
                        Create  a Lambda function with the console in the Ama-
                        zon Web Services Lambda Developer Guide .

              Mode -> (string)
                 Whether the container hosts a single model or  multiple  mod-
                 els.

              ModelDataUrl -> (string)
                 The  S3  path  where  the  model artifacts, which result from
                 model training, are stored. This path must point to a  single
                 gzip  compressed tar archive (.tar.gz suffix). The S3 path is
                 required for Amazon SageMaker built-in algorithms, but not if
                 you use your own algorithms. For more information on built-in
                 algorithms, see Common Parameters .

                 NOTE:
                     The model artifacts must be in an S3 bucket  that  is  in
                     the  same  region as the model or endpoint you are creat-
                     ing.

                 If you provide a value for this parameter,  Amazon  SageMaker
                 uses  Amazon  Web Services Security Token Service to download
                 model artifacts from the S3 path you provide. Amazon Web Ser-
                 vices  STS  is activated in your IAM user account by default.
                 If you previously deactivated Amazon Web Services STS  for  a
                 region,  you  need  to reactivate Amazon Web Services STS for
                 that region. For more information, see Activating and Deacti-
                 vating  Amazon  Web  Services  STS  in an Amazon Web Services
                 Region in the Amazon Web Services Identity and Access Manage-
                 ment User Guide .

                 WARNING:
                     If you use a built-in algorithm to create a model, Amazon
                     SageMaker requires that you provide  a  S3  path  to  the
                     model artifacts in ModelDataUrl .

              Environment -> (map)
                 The  environment  variables  to  set in the Docker container.
                 Each key and value in the Environment string  to  string  map
                 can have length of up to 1024. We support up to 16 entries in
                 the map.

                 key -> (string)

                 value -> (string)

              ModelPackageName -> (string)
                 The name or Amazon Resource Name (ARN) of the  model  package
                 to use to create the model.

              InferenceSpecificationName -> (string)
                 The  inference  specification  name in the model package ver-
                 sion.

              MultiModelConfig -> (structure)
                 Specifies additional configuration for multi-model endpoints.

                 ModelCacheSetting -> (string)
                     Whether  to  cache  models for a multi-model endpoint. By
                     default, multi-model endpoints cache  models  so  that  a
                     model does not have to be loaded into memory each time it
                     is invoked. Some use cases  do  not  benefit  from  model
                     caching. For example, if an endpoint hosts a large number
                     of models that are each invoked  infrequently,  the  end-
                     point  might perform better if you disable model caching.
                     To disable model caching, set the value of this parameter
                     to Disabled .

       InferenceExecutionConfig -> (structure)
          Specifies  details  of  how containers in a multi-container endpoint
          are called.

          Mode -> (string)
              How containers in a multi-container are run. The following  val-
              ues are valid.

              o SERIAL - Containers run as a serial pipeline.

              o DIRECT  -  Only  the  individual container that you specify is
                run.

       ExecutionRoleArn -> (string)
          The Amazon Resource Name (ARN) of the IAM role  that  you  specified
          for the model.

       VpcConfig -> (structure)
          A   VpcConfig  object  that  specifies  the  VPC that this model has
          access to. For more information, see Protect Endpoints by  Using  an
          Amazon Virtual Private Cloud

          SecurityGroupIds -> (list)
              The VPC security group IDs, in the form sg-xxxxxxxx. Specify the
              security groups for the VPC that is  specified  in  the  Subnets
              field.

              (string)

          Subnets -> (list)
              The  ID  of  the subnets in the VPC to which you want to connect
              your training job or model. For information about the availabil-
              ity of specific instance types, see Supported Instance Types and
              Availability Zones .

              (string)

       CreationTime -> (timestamp)
          A timestamp that shows when the model was created.

       ModelArn -> (string)
          The Amazon Resource Name (ARN) of the model.

       EnableNetworkIsolation -> (boolean)
          If True , no inbound or outbound network calls can  be  made  to  or
          from the model container.



                                                              DESCRIBE-MODEL()

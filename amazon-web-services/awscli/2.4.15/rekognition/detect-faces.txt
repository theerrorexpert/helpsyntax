DETECT-FACES()                                                  DETECT-FACES()



NAME
       detect-faces -

DESCRIPTION
       Detects faces within an image that is provided as input.
          DetectFaces  detects  the  100  largest faces in the image. For each
          face detected, the operation returns  face  details.  These  details
          include  a  bounding  box  of the face, a confidence value (that the
          bounding box contains a face), and a fixed set of attributes such as
          facial  landmarks (for example, coordinates of eye and mouth), pres-
          ence of beard, sunglasses, and so on.

       The face-detection algorithm is most effective on  frontal  faces.  For
       non-frontal or obscured faces, the algorithm might not detect the faces
       or might detect faces with lower confidence.

       You pass the input image either as base64-encoded image bytes or  as  a
       reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
       call Amazon Rekognition operations, passing image  bytes  is  not  sup-
       ported. The image must be either a PNG or JPEG formatted file.

       NOTE:
          This  is  a stateless API operation. That is, the operation does not
          persist any data.

       This operation requires permissions to perform the  rekognition:Detect-
       Faces action.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            detect-faces
          [--image <value>]
          [--attributes <value>]
          [--image-bytes <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --image (structure)
          The  input image as base64-encoded bytes or an S3 object. If you use
          the  AWS  CLI  to  call  Amazon  Rekognition   operations,   passing
          base64-encoded image bytes is not supported.

          If  you  are  using an AWS SDK to call Amazon Rekognition, you might
          not need to base64-encode image bytes passed using the Bytes  field.
          For more information, see Images in the Amazon Rekognition developer
          guide.

          To specify a local file use --image-bytes instead.

          Bytes -> (blob)
              Blob of image bytes up to 5 MBs.

          S3Object -> (structure)
              Identifies an S3 object as the image source.

              Bucket -> (string)
                 Name of the S3 bucket.

              Name -> (string)
                 S3 object key name.

              Version -> (string)
                 If the bucket is versioning  enabled,  you  can  specify  the
                 object version.

       Shorthand Syntax:

          Bytes=blob,S3Object={Bucket=string,Name=string,Version=string}

       JSON Syntax:

          {
            "Bytes": blob,
            "S3Object": {
              "Bucket": "string",
              "Name": "string",
              "Version": "string"
            }
          }

       --attributes (list)
          An  array  of facial attributes you want to be returned. This can be
          the default list of attributes or all attributes. If you don't spec-
          ify  a  value for Attributes or if you specify ["DEFAULT"] , the API
          returns the following subset of  facial  attributes:  BoundingBox  ,
          Confidence , Pose , Quality , and Landmarks . If you provide ["ALL"]
          , all facial attributes are returned, but the operation takes longer
          to complete.

          If you provide both, ["ALL", "DEFAULT"] , the service uses a logical
          AND operator to determine which attributes to return (in this  case,
          all attributes).

          (string)

       Syntax:

          "string" "string" ...

          Where valid values are:
            DEFAULT
            ALL

       --image-bytes (blob)
          The content of the image to be uploaded. To specify the content of a
          local file use the fileb:// prefix. Example: fileb://image.png

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       To detect faces in an image

       The following detect-faces command detects faces in the specified image
       stored in an Amazon S3 bucket.

          aws rekognition detect-faces \
              --image '{"S3Object":{"Bucket":"MyImageS3Bucket","Name":"MyFriend.jpg"}}' \
              --attributes "ALL"

       Output:

          {
              "FaceDetails": [
                  {
                      "Confidence": 100.0,
                      "Eyeglasses": {
                          "Confidence": 98.91107940673828,
                          "Value": false
                      },
                      "Sunglasses": {
                          "Confidence": 99.7966537475586,
                          "Value": false
                      },
                      "Gender": {
                          "Confidence": 99.56611633300781,
                          "Value": "Male"
                      },
                      "Landmarks": [
                          {
                              "Y": 0.26721030473709106,
                              "X": 0.6204193830490112,
                              "Type": "eyeLeft"
                          },
                          {
                              "Y": 0.26831310987472534,
                              "X": 0.6776827573776245,
                              "Type": "eyeRight"
                          },
                          {
                              "Y": 0.3514654338359833,
                              "X": 0.6241428852081299,
                              "Type": "mouthLeft"
                          },
                          {
                              "Y": 0.35258132219314575,
                              "X": 0.6713621020317078,
                              "Type": "mouthRight"
                          },
                          {
                              "Y": 0.3140771687030792,
                              "X": 0.6428444981575012,
                              "Type": "nose"
                          },
                          {
                              "Y": 0.24662546813488007,
                              "X": 0.6001564860343933,
                              "Type": "leftEyeBrowLeft"
                          },
                          {
                              "Y": 0.24326619505882263,
                              "X": 0.6303644776344299,
                              "Type": "leftEyeBrowRight"
                          },
                          {
                              "Y": 0.23818562924861908,
                              "X": 0.6146903038024902,
                              "Type": "leftEyeBrowUp"
                          },
                          {
                              "Y": 0.24373626708984375,
                              "X": 0.6640064716339111,
                              "Type": "rightEyeBrowLeft"
                          },
                          {
                              "Y": 0.24877218902111053,
                              "X": 0.7025929093360901,
                              "Type": "rightEyeBrowRight"
                          },
                          {
                              "Y": 0.23938551545143127,
                              "X": 0.6823262572288513,
                              "Type": "rightEyeBrowUp"
                          },
                          {
                              "Y": 0.265746533870697,
                              "X": 0.6112898588180542,
                              "Type": "leftEyeLeft"
                          },
                          {
                              "Y": 0.2676128149032593,
                              "X": 0.6317071914672852,
                              "Type": "leftEyeRight"
                          },
                          {
                              "Y": 0.262735515832901,
                              "X": 0.6201658248901367,
                              "Type": "leftEyeUp"
                          },
                          {
                              "Y": 0.27025148272514343,
                              "X": 0.6206279993057251,
                              "Type": "leftEyeDown"
                          },
                          {
                              "Y": 0.268223375082016,
                              "X": 0.6658390760421753,
                              "Type": "rightEyeLeft"
                          },
                          {
                              "Y": 0.2672517001628876,
                              "X": 0.687832236289978,
                              "Type": "rightEyeRight"
                          },
                          {
                              "Y": 0.26383838057518005,
                              "X": 0.6769183874130249,
                              "Type": "rightEyeUp"
                          },
                          {
                              "Y": 0.27138751745224,
                              "X": 0.676596462726593,
                              "Type": "rightEyeDown"
                          },
                          {
                              "Y": 0.32283174991607666,
                              "X": 0.6350004076957703,
                              "Type": "noseLeft"
                          },
                          {
                              "Y": 0.3219289481639862,
                              "X": 0.6567046642303467,
                              "Type": "noseRight"
                          },
                          {
                              "Y": 0.3420318365097046,
                              "X": 0.6450609564781189,
                              "Type": "mouthUp"
                          },
                          {
                              "Y": 0.3664324879646301,
                              "X": 0.6455618143081665,
                              "Type": "mouthDown"
                          },
                          {
                              "Y": 0.26721030473709106,
                              "X": 0.6204193830490112,
                              "Type": "leftPupil"
                          },
                          {
                              "Y": 0.26831310987472534,
                              "X": 0.6776827573776245,
                              "Type": "rightPupil"
                          },
                          {
                              "Y": 0.26343393325805664,
                              "X": 0.5946047306060791,
                              "Type": "upperJawlineLeft"
                          },
                          {
                              "Y": 0.3543180525302887,
                              "X": 0.6044883728027344,
                              "Type": "midJawlineLeft"
                          },
                          {
                              "Y": 0.4084877669811249,
                              "X": 0.6477024555206299,
                              "Type": "chinBottom"
                          },
                          {
                              "Y": 0.3562754988670349,
                              "X": 0.707981526851654,
                              "Type": "midJawlineRight"
                          },
                          {
                              "Y": 0.26580461859703064,
                              "X": 0.7234612107276917,
                              "Type": "upperJawlineRight"
                          }
                      ],
                      "Pose": {
                          "Yaw": -3.7351467609405518,
                          "Roll": -0.10309021919965744,
                          "Pitch": 0.8637830018997192
                      },
                      "Emotions": [
                          {
                              "Confidence": 8.74203109741211,
                              "Type": "SURPRISED"
                          },
                          {
                              "Confidence": 2.501944065093994,
                              "Type": "ANGRY"
                          },
                          {
                              "Confidence": 0.7378743290901184,
                              "Type": "DISGUSTED"
                          },
                          {
                              "Confidence": 3.5296201705932617,
                              "Type": "HAPPY"
                          },
                          {
                              "Confidence": 1.7162904739379883,
                              "Type": "SAD"
                          },
                          {
                              "Confidence": 9.518536567687988,
                              "Type": "CONFUSED"
                          },
                          {
                              "Confidence": 0.45474427938461304,
                              "Type": "FEAR"
                          },
                          {
                              "Confidence": 72.79895782470703,
                              "Type": "CALM"
                          }
                      ],
                      "AgeRange": {
                          "High": 48,
                          "Low": 32
                      },
                      "EyesOpen": {
                          "Confidence": 98.93987274169922,
                          "Value": true
                      },
                      "BoundingBox": {
                          "Width": 0.12368916720151901,
                          "Top": 0.16007372736930847,
                          "Left": 0.5901257991790771,
                          "Height": 0.25140416622161865
                      },
                      "Smile": {
                          "Confidence": 93.4493179321289,
                          "Value": false
                      },
                      "MouthOpen": {
                          "Confidence": 90.53053283691406,
                          "Value": false
                      },
                      "Quality": {
                          "Sharpness": 95.51618957519531,
                          "Brightness": 65.29893493652344
                      },
                      "Mustache": {
                          "Confidence": 89.85221099853516,
                          "Value": false
                      },
                      "Beard": {
                          "Confidence": 86.1991195678711,
                          "Value": true
                      }
                  }
              ]
          }

       For  more  information,  see  Detecting Faces in an Image in the Amazon
       Rekognition Developer Guide.

OUTPUT
       FaceDetails -> (list)
          Details of each face found in the image.

          (structure)
              Structure containing attributes of the face that  the  algorithm
              detected.

              A   FaceDetail   object   contains  either  the  default  facial
              attributes or all facial attributes. The default attributes  are
              BoundingBox , Confidence , Landmarks , Pose , and Quality .
                 GetFaceDetection  is the only Amazon Rekognition Video stored
                 video operation that can return a FaceDetail object with  all
                 attributes.  To  specify  which attributes to return, use the
                 FaceAttributes input parameter for  StartFaceDetection .  The
                 following Amazon Rekognition Video operations return only the
                 default attributes. The corresponding Start operations  don't
                 have a FaceAttributes input parameter.

              o GetCelebrityRecognition

              o GetPersonTracking

              o GetFaceSearch

              The Amazon Rekognition Image  DetectFaces and  IndexFaces opera-
              tions  can  return  all  facial  attributes.  To  specify  which
              attributes  to  return,  use  the Attributes input parameter for
              DetectFaces . For IndexFaces , use  the  DetectAttributes  input
              parameter.

              BoundingBox -> (structure)
                 Bounding box of the face. Default attribute.

                 Width -> (float)
                     Width of the bounding box as a ratio of the overall image
                     width.

                 Height -> (float)
                     Height of the bounding box as  a  ratio  of  the  overall
                     image height.

                 Left -> (float)
                     Left coordinate of the bounding box as a ratio of overall
                     image width.

                 Top -> (float)
                     Top coordinate of the bounding box as a ratio of  overall
                     image height.

              AgeRange -> (structure)
                 The  estimated  age range, in years, for the face. Low repre-
                 sents the lowest estimated age and High represents the  high-
                 est estimated age.

                 Low -> (integer)
                     The lowest estimated age.

                 High -> (integer)
                     The highest estimated age.

              Smile -> (structure)
                 Indicates  whether or not the face is smiling, and the confi-
                 dence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the face is  smiling
                     or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Eyeglasses -> (structure)
                 Indicates whether or not the face is wearing eye glasses, and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the face is  wearing
                     eye glasses or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Sunglasses -> (structure)
                 Indicates  whether or not the face is wearing sunglasses, and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the face is  wearing
                     sunglasses or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Gender -> (structure)
                 The predicted gender of a detected face.

                 Value -> (string)
                     The predicted gender of the face.

                 Confidence -> (float)
                     Level of confidence in the prediction.

              Beard -> (structure)
                 Indicates whether or not the face has a beard, and the confi-
                 dence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the face  has  beard
                     or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Mustache -> (structure)
                 Indicates  whether  or  not  the face has a mustache, and the
                 confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the  face  has  mus-
                     tache or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              EyesOpen -> (structure)
                 Indicates  whether  or not the eyes on the face are open, and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether the eyes on the face
                     are open.

                 Confidence -> (float)
                     Level of confidence in the determination.

              MouthOpen -> (structure)
                 Indicates  whether  or not the mouth on the face is open, and
                 the confidence level in the determination.

                 Value -> (boolean)
                     Boolean value that indicates whether  the  mouth  on  the
                     face is open or not.

                 Confidence -> (float)
                     Level of confidence in the determination.

              Emotions -> (list)
                 The emotions that appear to be expressed on the face, and the
                 confidence level in the determination. The API is only making
                 a  determination  of  the  physical  appearance of a person's
                 face. It is not a determination of the persons internal  emo-
                 tional  state and should not be used in such a way. For exam-
                 ple, a person pretending to have a sad face might not be  sad
                 emotionally.

                 (structure)
                     The emotions that appear to be expressed on the face, and
                     the confidence level in the  determination.  The  API  is
                     only making a determination of the physical appearance of
                     a person's face. It is not a determination of the persons
                     internal emotional state and should not be used in such a
                     way. For example, a person pretending to have a sad  face
                     might not be sad emotionally.

                     Type -> (string)
                        Type of emotion detected.

                     Confidence -> (float)
                        Level of confidence in the determination.

              Landmarks -> (list)
                 Indicates  the  location  of  landmarks  on the face. Default
                 attribute.

                 (structure)
                     Indicates the location of the landmark on the face.

                     Type -> (string)
                        Type of landmark.

                     X -> (float)
                        The x-coordinate of the landmark expressed as a  ratio
                        of  the  width  of the image. The x-coordinate is mea-
                        sured from the left-side of the image. For example, if
                        the  image  is 700 pixels wide and the x-coordinate of
                        the landmark is at 350 pixels, this value is 0.5.

                     Y -> (float)
                        The y-coordinate of the landmark expressed as a  ratio
                        of  the  height of the image. The y-coordinate is mea-
                        sured from the top of the image. For example,  if  the
                        image height is 200 pixels and the y-coordinate of the
                        landmark is at 50 pixels, this value is 0.25.

              Pose -> (structure)
                 Indicates the pose of the face as determined  by  its  pitch,
                 roll, and yaw. Default attribute.

                 Roll -> (float)
                     Value representing the face rotation on the roll axis.

                 Yaw -> (float)
                     Value representing the face rotation on the yaw axis.

                 Pitch -> (float)
                     Value representing the face rotation on the pitch axis.

              Quality -> (structure)
                 Identifies image brightness and sharpness. Default attribute.

                 Brightness -> (float)
                     Value representing brightness of the  face.  The  service
                     returns  a  value between 0 and 100 (inclusive). A higher
                     value indicates a brighter face image.

                 Sharpness -> (float)
                     Value representing sharpness of  the  face.  The  service
                     returns  a  value between 0 and 100 (inclusive). A higher
                     value indicates a sharper face image.

              Confidence -> (float)
                 Confidence level that the bounding box contains a  face  (and
                 not a different object such as a tree). Default attribute.

       OrientationCorrection -> (string)
          The value of OrientationCorrection is always null.

          If the input image is in .jpeg format, it might contain exchangeable
          image file format (Exif) metadata that includes the image's orienta-
          tion.  Amazon  Rekognition uses this orientation information to per-
          form image correction. The bounding box coordinates  are  translated
          to  represent  object locations after the orientation information in
          the Exif metadata is used to correct the image  orientation.  Images
          in .png format don't contain Exif metadata.

          Amazon  Rekognition  doesnt  perform  image correction for images in
          .png format and .jpeg images without orientation information in  the
          image  Exif metadata. The bounding box coordinates aren't translated
          and represent the object locations before the image is rotated.



                                                                DETECT-FACES()

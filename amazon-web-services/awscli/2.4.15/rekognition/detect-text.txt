DETECT-TEXT()                                                    DETECT-TEXT()



NAME
       detect-text -

DESCRIPTION
       Detects  text  in the input image and converts it into machine-readable
       text.

       Pass the input image as base64-encoded image bytes or as a reference to
       an  image in an Amazon S3 bucket. If you use the AWS CLI to call Amazon
       Rekognition operations, you must pass it as a reference to an image  in
       an  Amazon  S3 bucket. For the AWS CLI, passing image bytes is not sup-
       ported. The image must be either a .png or .jpeg formatted file.

       The DetectText operation returns text in  an  array  of   TextDetection
       elements, TextDetections . Each TextDetection element provides informa-
       tion about a single word or line of  text  that  was  detected  in  the
       image.

       A  word is one or more script characters that are not separated by spa-
       ces. DetectText can detect up to 100 words in an image.

       A line is a string of equally spaced words. A line isn't necessarily  a
       complete  sentence.  For example, a driver's license number is detected
       as a line. A line ends when there is no aligned text after it. Also,  a
       line  ends  when  there  is  a large gap between words, relative to the
       length of the words. This means, depending on the  gap  between  words,
       Amazon  Rekognition  may  detect  multiple lines in text aligned in the
       same direction. Periods don't represent the end of a line.  If  a  sen-
       tence  spans  multiple lines, the DetectText operation returns multiple
       lines.

       To determine whether a TextDetection element is a line  of  text  or  a
       word, use the TextDetection object Type field.

       To  be  detected, text must be within +/- 90 degrees orientation of the
       horizontal axis.

       For more information, see DetectText in the Amazon  Rekognition  Devel-
       oper Guide.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            detect-text
          [--image <value>]
          [--filters <value>]
          [--image-bytes <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --image (structure)
          The  input  image as base64-encoded bytes or an Amazon S3 object. If
          you use the AWS CLI to call Amazon Rekognition operations, you can't
          pass image bytes.

          If  you  are  using an AWS SDK to call Amazon Rekognition, you might
          not need to base64-encode image bytes passed using the Bytes  field.
          For more information, see Images in the Amazon Rekognition developer
          guide.

          To specify a local file use --image-bytes instead.

          Bytes -> (blob)
              Blob of image bytes up to 5 MBs.

          S3Object -> (structure)
              Identifies an S3 object as the image source.

              Bucket -> (string)
                 Name of the S3 bucket.

              Name -> (string)
                 S3 object key name.

              Version -> (string)
                 If the bucket is versioning  enabled,  you  can  specify  the
                 object version.

       Shorthand Syntax:

          Bytes=blob,S3Object={Bucket=string,Name=string,Version=string}

       JSON Syntax:

          {
            "Bytes": blob,
            "S3Object": {
              "Bucket": "string",
              "Name": "string",
              "Version": "string"
            }
          }

       --filters (structure)
          Optional parameters that let you set the criteria that the text must
          meet to be included in your response.

          WordFilter -> (structure)
              A set of parameters that allow you to filter out certain results
              from your returned results.

              MinConfidence -> (float)
                 Sets  the  confidence of word detection. Words with detection
                 confidence below this will be excluded from the result.  Val-
                 ues  should  be  between 50 and 100 as Text in Video will not
                 return any result below 50.

              MinBoundingBoxHeight -> (float)
                 Sets the minimum height of the word bounding box. Words  with
                 bounding  box heights lesser than this value will be excluded
                 from the result. Value is relative to the video frame height.

              MinBoundingBoxWidth -> (float)
                 Sets  the  minimum width of the word bounding box. Words with
                 bounding boxes widths lesser than this value will be excluded
                 from  the result. Value is relative to the video frame width.

          RegionsOfInterest -> (list)
              A Filter focusing on a certain area of the image. Uses a  Bound-
              ingBox object to set the region of the image.

              (structure)
                 Specifies a location within the frame that Rekognition checks
                 for text. Uses a BoundingBox object to set a  region  of  the
                 screen.

                 A  word  is  included  in the region if the word is more than
                 half in that region. If there is more than  one  region,  the
                 word  will  be  compared  with all regions of the screen. Any
                 word more than half in a region is kept in the results.

                 BoundingBox -> (structure)
                     The box representing a region of interest on screen.

                     Width -> (float)
                        Width of the bounding box as a ratio  of  the  overall
                        image width.

                     Height -> (float)
                        Height  of  the bounding box as a ratio of the overall
                        image height.

                     Left -> (float)
                        Left coordinate of the bounding  box  as  a  ratio  of
                        overall image width.

                     Top -> (float)
                        Top coordinate of the bounding box as a ratio of over-
                        all image height.

       JSON Syntax:

          {
            "WordFilter": {
              "MinConfidence": float,
              "MinBoundingBoxHeight": float,
              "MinBoundingBoxWidth": float
            },
            "RegionsOfInterest": [
              {
                "BoundingBox": {
                  "Width": float,
                  "Height": float,
                  "Left": float,
                  "Top": float
                }
              }
              ...
            ]
          }

       --image-bytes (blob)
          The content of the image to be uploaded. To specify the content of a
          local file use the fileb:// prefix. Example: fileb://image.png

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       To detect text in an image

       The  following detect-text command detects text in the specified image.

          aws rekognition detect-text \
              --image '{"S3Object":{"Bucket":"MyImageS3Bucket","Name":"ExamplePicture.jpg"}}'

       Output:

          {
              "TextDetections": [
                  {
                      "Geometry": {
                          "BoundingBox": {
                              "Width": 0.24624845385551453,
                              "Top": 0.28288066387176514,
                              "Left": 0.391388863325119,
                              "Height": 0.022687450051307678
                          },
                          "Polygon": [
                              {
                                  "Y": 0.28288066387176514,
                                  "X": 0.391388863325119
                              },
                              {
                                  "Y": 0.2826388478279114,
                                  "X": 0.6376373171806335
                              },
                              {
                                  "Y": 0.30532628297805786,
                                  "X": 0.637677013874054
                              },
                              {
                                  "Y": 0.305568128824234,
                                  "X": 0.39142853021621704
                              }
                          ]
                      },
                      "Confidence": 94.35709381103516,
                      "DetectedText": "ESTD 1882",
                      "Type": "LINE",
                      "Id": 0
                  },
                  {
                      "Geometry": {
                          "BoundingBox": {
                              "Width": 0.33933889865875244,
                              "Top": 0.32603850960731506,
                              "Left": 0.34534579515457153,
                              "Height": 0.07126858830451965
                          },
                          "Polygon": [
                              {
                                  "Y": 0.32603850960731506,
                                  "X": 0.34534579515457153
                              },
                              {
                                  "Y": 0.32633158564567566,
                                  "X": 0.684684693813324
                              },
                              {
                                  "Y": 0.3976001739501953,
                                  "X": 0.684575080871582
                              },
                              {
                                  "Y": 0.3973070979118347,
                                  "X": 0.345236212015152
                              }
                          ]
                      },
                      "Confidence": 99.95779418945312,
                      "DetectedText": "BRAINS",
                      "Type": "LINE",
                      "Id": 1
                  },
                  {
                      "Confidence": 97.22098541259766,
                      "Geometry": {
                          "BoundingBox": {
                              "Width": 0.061079490929841995,
                              "Top": 0.2843210697174072,
                              "Left": 0.391391396522522,
                              "Height": 0.021029088646173477
                          },
                          "Polygon": [
                              {
                                  "Y": 0.2843210697174072,
                                  "X": 0.391391396522522
                              },
                              {
                                  "Y": 0.2828207015991211,
                                  "X": 0.4524524509906769
                              },
                              {
                                  "Y": 0.3038259446620941,
                                  "X": 0.4534534513950348
                              },
                              {
                                  "Y": 0.30532634258270264,
                                  "X": 0.3923923969268799
                              }
                          ]
                      },
                      "DetectedText": "ESTD",
                      "ParentId": 0,
                      "Type": "WORD",
                      "Id": 2
                  },
                  {
                      "Confidence": 91.49320983886719,
                      "Geometry": {
                          "BoundingBox": {
                              "Width": 0.07007007300853729,
                              "Top": 0.2828207015991211,
                              "Left": 0.5675675868988037,
                              "Height": 0.02250562608242035
                          },
                          "Polygon": [
                              {
                                  "Y": 0.2828207015991211,
                                  "X": 0.5675675868988037
                              },
                              {
                                  "Y": 0.2828207015991211,
                                  "X": 0.6376376152038574
                              },
                              {
                                  "Y": 0.30532634258270264,
                                  "X": 0.6376376152038574
                              },
                              {
                                  "Y": 0.30532634258270264,
                                  "X": 0.5675675868988037
                              }
                          ]
                      },
                      "DetectedText": "1882",
                      "ParentId": 0,
                      "Type": "WORD",
                      "Id": 3
                  },
                  {
                      "Confidence": 99.95779418945312,
                      "Geometry": {
                          "BoundingBox": {
                              "Width": 0.33933934569358826,
                              "Top": 0.32633158564567566,
                              "Left": 0.3453453481197357,
                              "Height": 0.07127484679222107
                          },
                          "Polygon": [
                              {
                                  "Y": 0.32633158564567566,
                                  "X": 0.3453453481197357
                              },
                              {
                                  "Y": 0.32633158564567566,
                                  "X": 0.684684693813324
                              },
                              {
                                  "Y": 0.39759939908981323,
                                  "X": 0.6836836934089661
                              },
                              {
                                  "Y": 0.39684921503067017,
                                  "X": 0.3453453481197357
                              }
                          ]
                      },
                      "DetectedText": "BRAINS",
                      "ParentId": 1,
                      "Type": "WORD",
                      "Id": 4
                  }
              ]
          }

OUTPUT
       TextDetections -> (list)
          An array of text that was detected in the input image.

          (structure)
              Information about a word or line of text detected by  DetectText
              .

              The DetectedText field contains the text that Amazon Rekognition
              detected in the image.

              Every word and line has an identifier (Id ). Each  word  belongs
              to  a  line and has a parent identifier (ParentId ) that identi-
              fies the line of text in which the word appears. The word Id  is
              also an index for the word within a line of words.

              For  more information, see Detecting Text in the Amazon Rekogni-
              tion Developer Guide.

              DetectedText -> (string)
                 The word or line of text recognized by Amazon Rekognition.

              Type -> (string)
                 The type of text that was detected.

              Id -> (integer)
                 The identifier for the detected text. The identifier is  only
                 unique for a single call to DetectText .

              ParentId -> (integer)
                 The Parent identifier for the detected text identified by the
                 value of ID . If the type of detected  text  is  LINE  ,  the
                 value of ParentId is Null .

              Confidence -> (float)
                 The confidence that Amazon Rekognition has in the accuracy of
                 the detected text and the accuracy  of  the  geometry  points
                 around the detected text.

              Geometry -> (structure)
                 The  location  of the detected text on the image. Includes an
                 axis aligned coarse bounding box surrounding the text  and  a
                 finer grain polygon for more accurate spatial information.

                 BoundingBox -> (structure)
                     An  axis-aligned  coarse  representation  of the detected
                     item's location on the image.

                     Width -> (float)
                        Width of the bounding box as a ratio  of  the  overall
                        image width.

                     Height -> (float)
                        Height  of  the bounding box as a ratio of the overall
                        image height.

                     Left -> (float)
                        Left coordinate of the bounding  box  as  a  ratio  of
                        overall image width.

                     Top -> (float)
                        Top coordinate of the bounding box as a ratio of over-
                        all image height.

                 Polygon -> (list)
                     Within the bounding box, a  fine-grained  polygon  around
                     the detected item.

                     (structure)
                        The  X and Y coordinates of a point on an image. The X
                        and Y values returned are ratios of the overall  image
                        size.  For  example, if the input image is 700x200 and
                        the operation returns X=0.5 and Y=0.25, then the point
                        is at the (350,50) pixel coordinate on the image.

                        An  array  of  Point objects, Polygon , is returned by
                        DetectText and by  DetectCustomLabels . Polygon repre-
                        sents  a  fine-grained polygon around a detected item.
                        For more  information,  see  Geometry  in  the  Amazon
                        Rekognition Developer Guide.

                        X -> (float)
                            The  value  of  the  X coordinate for a point on a
                            Polygon .

                        Y -> (float)
                            The value of the Y coordinate for  a  point  on  a
                            Polygon .

       TextModelVersion -> (string)
          The model version used to detect text.



                                                                 DETECT-TEXT()

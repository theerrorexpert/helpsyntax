DETECT-MODERATION-LABELS()                          DETECT-MODERATION-LABELS()



NAME
       detect-moderation-labels -

DESCRIPTION
       Detects  unsafe  content  in  a specified JPEG or PNG format image. Use
       DetectModerationLabels to moderate images depending  on  your  require-
       ments.  For  example,  you  might  want  to  filter images that contain
       nudity, but not images containing suggestive content.

       To filter images, use the labels returned by DetectModerationLabels  to
       determine which types of content are appropriate.

       For  information  about moderation labels, see Detecting Unsafe Content
       in the Amazon Rekognition Developer Guide.

       You pass the input image either as base64-encoded image bytes or  as  a
       reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
       call Amazon Rekognition operations, passing image  bytes  is  not  sup-
       ported. The image must be either a PNG or JPEG formatted file.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            detect-moderation-labels
          [--image <value>]
          [--min-confidence <value>]
          [--human-loop-config <value>]
          [--image-bytes <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --image (structure)
          The  input image as base64-encoded bytes or an S3 object. If you use
          the  AWS  CLI  to  call  Amazon  Rekognition   operations,   passing
          base64-encoded image bytes is not supported.

          If  you  are  using an AWS SDK to call Amazon Rekognition, you might
          not need to base64-encode image bytes passed using the Bytes  field.
          For more information, see Images in the Amazon Rekognition developer
          guide.

          To specify a local file use --image-bytes instead.

          Bytes -> (blob)
              Blob of image bytes up to 5 MBs.

          S3Object -> (structure)
              Identifies an S3 object as the image source.

              Bucket -> (string)
                 Name of the S3 bucket.

              Name -> (string)
                 S3 object key name.

              Version -> (string)
                 If the bucket is versioning  enabled,  you  can  specify  the
                 object version.

       Shorthand Syntax:

          Bytes=blob,S3Object={Bucket=string,Name=string,Version=string}

       JSON Syntax:

          {
            "Bytes": blob,
            "S3Object": {
              "Bucket": "string",
              "Name": "string",
              "Version": "string"
            }
          }

       --min-confidence (float)
          Specifies  the  minimum  confidence  level for the labels to return.
          Amazon Rekognition doesn't return any labels with a confidence level
          lower than this specified value.

          If  you  don't  specify MinConfidence , the operation returns labels
          with confidence values greater than or equal to 50 percent.

       --human-loop-config (structure)
          Sets up  the  configuration  for  human  evaluation,  including  the
          FlowDefinition the image will be sent to.

          HumanLoopName -> (string)
              The name of the human review used for this image. This should be
              kept unique within a region.

          FlowDefinitionArn -> (string)
              The Amazon Resource Name (ARN) of the flow definition.  You  can
              create   a   flow  definition  by  using  the  Amazon  Sagemaker
              CreateFlowDefinition Operation.

          DataAttributes -> (structure)
              Sets attributes of the input data.

              ContentClassifiers -> (list)
                 Sets whether the input image is free of personally  identifi-
                 able information.

                 (string)

       Shorthand Syntax:

          HumanLoopName=string,FlowDefinitionArn=string,DataAttributes={ContentClassifiers=[string,string]}

       JSON Syntax:

          {
            "HumanLoopName": "string",
            "FlowDefinitionArn": "string",
            "DataAttributes": {
              "ContentClassifiers": ["FreeOfPersonallyIdentifiableInformation"|"FreeOfAdultContent", ...]
            }
          }

       --image-bytes (blob)
          The content of the image to be uploaded. To specify the content of a
          local file use the fileb:// prefix. Example: fileb://image.png

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       To detect unsafe content in an image

       The following detect-moderation-labels command detects  unsafe  content
       in the specified image stored in an Amazon S3 bucket.

          aws rekognition detect-moderation-labels \
              --image "S3Object={Bucket=MyImageS3Bucket,Name=gun.jpg}"

       Output:

          {
              "ModerationModelVersion": "3.0",
              "ModerationLabels": [
                  {
                      "Confidence": 97.29618072509766,
                      "ParentName": "Violence",
                      "Name": "Weapon Violence"
                  },
                  {
                      "Confidence": 97.29618072509766,
                      "ParentName": "",
                      "Name": "Violence"
                  }
              ]
          }

       For  more information, see Detecting Unsafe Images in the Amazon Rekog-
       nition Developer Guide.

OUTPUT
       ModerationLabels -> (list)
          Array of detected Moderation labels and the  time,  in  milliseconds
          from the start of the video, they were detected.

          (structure)
              Provides  information  about  a  single  type  of inappropriate,
              unwanted, or offensive content found in an image or video.  Each
              type of moderated content has a label within a hierarchical tax-
              onomy. For more information, see Content moderation in the  Ama-
              zon Rekognition Developer Guide.

              Confidence -> (float)
                 Specifies the confidence that Amazon Rekognition has that the
                 label has been correctly identified.

                 If you don't specify the MinConfidence parameter in the  call
                 to DetectModerationLabels , the operation returns labels with
                 a confidence value greater than or equal to 50 percent.

              Name -> (string)
                 The label name for the type of unsafe content detected in the
                 image.

              ParentName -> (string)
                 The name for the parent label. Labels at the top level of the
                 hierarchy have the parent label "" .

       ModerationModelVersion -> (string)
          Version number of the moderation detection model that  was  used  to
          detect unsafe content.

       HumanLoopActivationOutput -> (structure)
          Shows the results of the human in the loop evaluation.

          HumanLoopArn -> (string)
              The Amazon Resource Name (ARN) of the HumanLoop created.

          HumanLoopActivationReasons -> (list)
              Shows if and why human review was needed.

              (string)

          HumanLoopActivationConditionsEvaluationResults -> (string)
              Shows  the result of condition evaluations, including those con-
              ditions which activated a human review.



                                                    DETECT-MODERATION-LABELS()

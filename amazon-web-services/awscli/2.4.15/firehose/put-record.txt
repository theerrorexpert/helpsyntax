PUT-RECORD()                                                      PUT-RECORD()



NAME
       put-record -

DESCRIPTION
       Writes a single data record into an Amazon Kinesis Data Firehose deliv-
       ery stream. To write multiple data records into a delivery stream,  use
       PutRecordBatch . Applications using these operations are referred to as
       producers.

       By default, each delivery stream can take in up to  2,000  transactions
       per  second,  5,000  records per second, or 5 MB per second. If you use
       PutRecord and  PutRecordBatch , the  limits  are  an  aggregate  across
       these  two  operations  for  each delivery stream. For more information
       about limits and how to request an increase, see  Amazon  Kinesis  Data
       Firehose Limits .

       You  must  specify  the name of the delivery stream and the data record
       when using  PutRecord . The data record consists of a  data  blob  that
       can  be  up to 1,000 KiB in size, and any kind of data. For example, it
       can be a segment from a log file,  geographic  location  data,  website
       clickstream data, and so on.

       Kinesis  Data  Firehose  buffers  records before delivering them to the
       destination. To disambiguate the data blobs at the destination, a  com-
       mon  solution is to use delimiters in the data, such as a newline (\n )
       or some other character unique within the data. This  allows  the  con-
       sumer  application to parse individual data items when reading the data
       from the destination.

       The PutRecord operation returns a RecordId , which is a  unique  string
       assigned to each record. Producer applications can use this ID for pur-
       poses such as auditability and investigation.

       If the PutRecord operation throws a ServiceUnavailableException ,  back
       off  and  retry.  If  the  exception  persists, it is possible that the
       throughput limits have been exceeded for the delivery stream.

       Data records sent to Kinesis Data Firehose are stored for 24 hours from
       the  time  they  are added to a delivery stream as it tries to send the
       records to the destination. If the destination is unreachable for  more
       than 24 hours, the data is no longer available.

       WARNING:
          Don't concatenate two or more base64 strings to form the data fields
          of your records. Instead, concatenate the  raw  data,  then  perform
          base64 encoding.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            put-record
          --delivery-stream-name <value>
          --record <value>
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --delivery-stream-name (string)
          The name of the delivery stream.

       --record (structure)
          The record.

          Data -> (blob)
              The  data blob, which is base64-encoded when the blob is serial-
              ized. The maximum size of the data blob, before base64-encoding,
              is 1,000 KiB.

       Shorthand Syntax:

          Data=blob

       JSON Syntax:

          {
            "Data": blob
          }

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       To write a record to a stream

       The  following put-record example writes data to a stream.  The data is
       encoded in Base64 format.

          aws firehose put-record \
              --delivery-stream-name my-stream \
              --record '{"Data":"SGVsbG8gd29ybGQ="}'

       Output:

          {
              "RecordId": "RjB5K/nnoGFHqwTsZlNd/TTqvjE8V5dsyXZTQn2JXrdpMTOwssyEb6nfC8fwf1whhwnItt4mvrn+gsqeK5jB7QjuLg283+Ps4Sz/j1Xujv31iDhnPdaLw4BOyM9Amv7PcCuB2079RuM0NhoakbyUymlwY8yt20G8X2420wu1jlFafhci4erAt7QhDEvpwuK8N1uOQ1EuaKZWxQHDzcG6tk1E49IPeD9k",
              "Encrypted": false
          }

       For more information, see Sending Data to an Amazon Kinesis Data  Fire-
       hose  Delivery  Stream  in  the  Amazon Kinesis Data Firehose Developer
       Guide.

OUTPUT
       RecordId -> (string)
          The ID of the record.

       Encrypted -> (boolean)
          Indicates whether server-side encryption (SSE)  was  enabled  during
          this operation.



                                                                  PUT-RECORD()

BATCH-GET-JOBS()                                              BATCH-GET-JOBS()



NAME
       batch-get-jobs -

DESCRIPTION
       Returns  a  list  of  resource  metadata for a given list of job names.
       After calling the ListJobs operation, you can call  this  operation  to
       access the data to which you have been granted permissions. This opera-
       tion supports all IAM permissions, including permission conditions that
       uses tags.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            batch-get-jobs
          --job-names <value>
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --job-names (list)
          A  list  of  job  names,  which might be the names returned from the
          ListJobs operation.

          (string)

       Syntax:

          "string" "string" ...

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       Jobs -> (list)
          A list of job definitions.

          (structure)
              Specifies a job definition.

              Name -> (string)
                 The name you assign to this job definition.

              Description -> (string)
                 A description of the job.

              LogUri -> (string)
                 This field is reserved for future use.

              Role -> (string)
                 The name or Amazon Resource Name (ARN) of the IAM role  asso-
                 ciated with this job.

              CreatedOn -> (timestamp)
                 The time and date that this job definition was created.

              LastModifiedOn -> (timestamp)
                 The last point in time when this job definition was modified.

              ExecutionProperty -> (structure)
                 An ExecutionProperty specifying the maximum number of concur-
                 rent runs allowed for this job.

                 MaxConcurrentRuns -> (integer)
                     The  maximum  number  of  concurrent runs allowed for the
                     job. The default is 1. An error  is  returned  when  this
                     threshold  is  reached. The maximum value you can specify
                     is controlled by a service limit.

              Command -> (structure)
                 The JobCommand that runs this job.

                 Name -> (string)
                     The name of the job command. For an Apache Spark ETL job,
                     this must be glueetl . For a Python shell job, it must be
                     pythonshell . For an Apache Spark streaming ETL job, this
                     must be gluestreaming .

                 ScriptLocation -> (string)
                     Specifies  the  Amazon Simple Storage Service (Amazon S3)
                     path to a script that runs a job.

                 PythonVersion -> (string)
                     The Python version being used to run a Python shell  job.
                     Allowed values are 2 or 3.

              DefaultArguments -> (map)
                 The  default  arguments for this job, specified as name-value
                 pairs.

                 You can specify arguments here that  your  own  job-execution
                 script  consumes,  as well as arguments that Glue itself con-
                 sumes.

                 For information about how to specify and consume your own Job
                 arguments,  see  the Calling Glue APIs in Python topic in the
                 developer guide.

                 For information about the key-value pairs that Glue  consumes
                 to  set  up your job, see the Special Parameters Used by Glue
                 topic in the developer guide.

                 key -> (string)

                 value -> (string)

              NonOverridableArguments -> (map)
                 Non-overridable  arguments  for  this   job,   specified   as
                 name-value pairs.

                 key -> (string)

                 value -> (string)

              Connections -> (structure)
                 The connections used for this job.

                 Connections -> (list)
                     A list of connections used by the job.

                     (string)

              MaxRetries -> (integer)
                 The  maximum number of times to retry this job after a JobRun
                 fails.

              AllocatedCapacity -> (integer)
                 This field is deprecated. Use MaxCapacity instead.

                 The number of Glue data processing units (DPUs) allocated  to
                 runs  of  this  job. You can allocate from 2 to 100 DPUs; the
                 default is 10. A DPU is  a  relative  measure  of  processing
                 power  that consists of 4 vCPUs of compute capacity and 16 GB
                 of memory. For more information, see the Glue pricing page  .

              Timeout -> (integer)
                 The  job  timeout in minutes. This is the maximum time that a
                 job run can consume resources before  it  is  terminated  and
                 enters  TIMEOUT  status.  The  default  is  2,880 minutes (48
                 hours).

              MaxCapacity -> (double)
                 For Glue version 1.0 or  earlier  jobs,  using  the  standard
                 worker  type, the number of Glue data processing units (DPUs)
                 that can be allocated when this job runs. A DPU is a relative
                 measure  of processing power that consists of 4 vCPUs of com-
                 pute capacity and 16 GB of memory. For more information,  see
                 the Glue pricing page .

                 Do not set Max Capacity if using WorkerType and NumberOfWork-
                 ers .

                 The value that can be allocated for  MaxCapacity  depends  on
                 whether  you  are running a Python shell job, an Apache Spark
                 ETL job, or an Apache Spark streaming ETL job:

                 o When  you  specify  a  Python  shell  job  (JobCommand.Name
                   ="pythonshell"),  you  can allocate either 0.0625 or 1 DPU.
                   The default is 0.0625 DPU.

                 o When you specify an Apache Spark ETL  job  (JobCommand.Name
                   ="glueetl")  or  Apache  Spark  streaming  ETL job (JobCom-
                   mand.Name ="gluestreaming"), you can allocate from 2 to 100
                   DPUs.  The  default is 10 DPUs. This job type cannot have a
                   fractional DPU allocation.

                 For Glue version 2.0 jobs, you cannot instead specify a Maxi-
                 mum  capacity . Instead, you should specify a Worker type and
                 the Number of workers .

              WorkerType -> (string)
                 The type of predefined worker that is allocated  when  a  job
                 runs. Accepts a value of Standard, G.1X, or G.2X.

                 o For  the Standard worker type, each worker provides 4 vCPU,
                   16 GB of memory and  a  50GB  disk,  and  2  executors  per
                   worker.

                 o For  the  G.1X  worker  type,  each worker maps to 1 DPU (4
                   vCPU, 16 GB of memory, 64 GB disk), and provides 1 executor
                   per worker. We recommend this worker type for memory-inten-
                   sive jobs.

                 o For the G.2X worker type, each worker  maps  to  2  DPU  (8
                   vCPU,  32 GB of memory, 128 GB disk), and provides 1 execu-
                   tor per worker. We recommend  this  worker  type  for  mem-
                   ory-intensive jobs.

              NumberOfWorkers -> (integer)
                 The  number of workers of a defined workerType that are allo-
                 cated when a job runs.

                 The maximum number of workers you can define are 299 for G.1X
                 , and 149 for G.2X .

              SecurityConfiguration -> (string)
                 The  name  of  the SecurityConfiguration structure to be used
                 with this job.

              NotificationProperty -> (structure)
                 Specifies configuration properties of a job notification.

                 NotifyDelayAfter -> (integer)
                     After a job run starts, the number  of  minutes  to  wait
                     before sending a job run delay notification.

              GlueVersion -> (string)
                 Glue  version  determines  the  versions  of Apache Spark and
                 Python that Glue supports. The Python version  indicates  the
                 version supported for jobs of type Spark.

                 For  more  information  about the available Glue versions and
                 corresponding Spark and Python versions, see Glue version  in
                 the developer guide.

                 Jobs  that  are  created  without  specifying  a Glue version
                 default to Glue 0.9.

       JobsNotFound -> (list)
          A list of names of jobs not found.

          (string)



                                                              BATCH-GET-JOBS()

LIST-INFERENCE-SCHEDULERS()                        LIST-INFERENCE-SCHEDULERS()



NAME
       list-inference-schedulers -

DESCRIPTION
       Retrieves  a  list  of all inference schedulers currently available for
       your account.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            list-inference-schedulers
          [--next-token <value>]
          [--max-results <value>]
          [--inference-scheduler-name-begins-with <value>]
          [--model-name <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --next-token (string)
          An opaque pagination token indicating where to continue the  listing
          of inference schedulers.

       --max-results (integer)
          Specifies the maximum number of inference schedulers to list.

       --inference-scheduler-name-begins-with (string)
          The  beginning of the name of the inference schedulers to be listed.

       --model-name (string)
          The name of the ML model used  by  the  inference  scheduler  to  be
          listed.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       NextToken -> (string)
          An  opaque pagination token indicating where to continue the listing
          of inference schedulers.

       InferenceSchedulerSummaries -> (list)
          Provides  information  about  the  specified  inference   scheduler,
          including data upload frequency, model name and ARN, and status.

          (structure)
              Contains  information  about  the  specific inference scheduler,
              including data delay offset, model name and ARN, status, and  so
              on.

              ModelName -> (string)
                 The name of the ML model used for the inference scheduler.

              ModelArn -> (string)
                 The  Amazon  Resource  Name (ARN) of the ML model used by the
                 inference scheduler.

              InferenceSchedulerName -> (string)
                 The name of the inference scheduler.

              InferenceSchedulerArn -> (string)
                 The Amazon Resource Name (ARN) of the inference scheduler.

              Status -> (string)
                 Indicates the status of the inference scheduler.

              DataDelayOffsetInMinutes -> (long)
                 A period of time (in minutes) by which inference on the  data
                 is  delayed after the data starts. For instance, if an offset
                 delay time of five minutes was selected, inference  will  not
                 begin  on the data until the first data measurement after the
                 five minute mark. For example, if five minutes  is  selected,
                 the  inference  scheduler will wake up at the configured fre-
                 quency with the additional five minute delay  time  to  check
                 the  customer  S3 bucket. The customer can upload data at the
                 same frequency and they don't need to stop  and  restart  the
                 scheduler when uploading new data.

              DataUploadFrequency -> (string)
                 How  often  data  is uploaded to the source S3 bucket for the
                 input data. This value is the length  of  time  between  data
                 uploads.  For instance, if you select 5 minutes, Amazon Look-
                 out for Equipment will  upload  the  real-time  data  to  the
                 source  bucket  once  every  5  minutes.  This frequency also
                 determines how often Amazon Lookout for  Equipment  starts  a
                 scheduled  inference on your data. In this example, it starts
                 once every 5 minutes.



                                                   LIST-INFERENCE-SCHEDULERS()

LIST-INFERENCE-EXECUTIONS()                        LIST-INFERENCE-EXECUTIONS()



NAME
       list-inference-executions -

DESCRIPTION
       Lists  all  inference executions that have been performed by the speci-
       fied inference scheduler.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            list-inference-executions
          [--next-token <value>]
          [--max-results <value>]
          --inference-scheduler-name <value>
          [--data-start-time-after <value>]
          [--data-end-time-before <value>]
          [--status <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --next-token (string)
          An opaque pagination token indicating where to continue the  listing
          of inference executions.

       --max-results (integer)
          Specifies the maximum number of inference executions to list.

       --inference-scheduler-name (string)
          The  name  of  the  inference  scheduler for the inference execution
          listed.

       --data-start-time-after (timestamp)
          The time reference in the  inferenced  dataset  after  which  Amazon
          Lookout for Equipment started the inference execution.

       --data-end-time-before (timestamp)
          The  time  reference  in  the inferenced dataset before which Amazon
          Lookout for Equipment stopped the inference execution.

       --status (string)
          The status of the inference execution.

          Possible values:

          o IN_PROGRESS

          o SUCCESS

          o FAILED

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       NextToken -> (string)
          An opaque pagination token indicating where to continue the  listing
          of inference executions.

       InferenceExecutionSummaries -> (list)
          Provides an array of information about the individual inference exe-
          cutions returned from the ListInferenceExecutions operation, includ-
          ing  model used, inference scheduler, data configuration, and so on.

          (structure)
              Contains information about  the  specific  inference  execution,
              including  input and output data configuration, inference sched-
              uling information, status, and so on.

              ModelName -> (string)
                 The name of the ML model being used for the inference  execu-
                 tion.

              ModelArn -> (string)
                 The  Amazon  Resource Name (ARN) of the ML model used for the
                 inference execution.

              InferenceSchedulerName -> (string)
                 The name of the inference scheduler being used for the infer-
                 ence execution.

              InferenceSchedulerArn -> (string)
                 The  Amazon  Resource  Name  (ARN) of the inference scheduler
                 being used for the inference execution.

              ScheduledStartTime -> (timestamp)
                 Indicates the start time at  which  the  inference  scheduler
                 began the specific inference execution.

              DataStartTime -> (timestamp)
                 Indicates  the  time  reference  in  the dataset at which the
                 inference execution began.

              DataEndTime -> (timestamp)
                 Indicates the time reference in  the  dataset  at  which  the
                 inference execution stopped.

              DataInputConfiguration -> (structure)
                 Specifies  configuration  information  for the input data for
                 the inference scheduler,  including  delimiter,  format,  and
                 dataset location.

                 S3InputConfiguration -> (structure)
                     Specifies  configuration  information  for the input data
                     for the inference, including S3 location of input  data..

                     Bucket -> (string)
                        The bucket containing the input dataset for the infer-
                        ence.

                     Prefix -> (string)
                        The prefix for the S3 bucket used for the  input  data
                        for the inference.

                 InputTimeZoneOffset -> (string)
                     Indicates  the  difference  between  your  time  zone and
                     Greenwich Mean Time (GMT).

                 InferenceInputNameConfiguration -> (structure)
                     Specifies configuration information for  the  input  data
                     for  the inference, including timestamp format and delim-
                     iter.

                     TimestampFormat -> (string)
                        The format of the timestamp, whether  Epoch  time,  or
                        standard, with or without hyphens (-).

                     ComponentTimestampDelimiter -> (string)
                        Indicates  the  delimiter character used between items
                        in the data.

              DataOutputConfiguration -> (structure)
                 Specifies configuration information for  the  output  results
                 from  for  the  inference  execution, including the output S3
                 location.

                 S3OutputConfiguration -> (structure)
                     Specifies  configuration  information  for   the   output
                     results from for the inference, output S3 location.

                     Bucket -> (string)
                        The  bucket  containing  the  output  results from the
                        inference

                     Prefix -> (string)
                        The prefix for the  S3  bucket  used  for  the  output
                        results from the inference.

                 KmsKeyId -> (string)
                     The  ID  number  for  the AWS KMS key used to encrypt the
                     inference output.

              CustomerResultObject -> (structure)
                 Bucket -> (string)
                     The name of the specific S3 bucket.

                 Key -> (string)
                     The AWS Key Management Service (AWS KMS) key  being  used
                     to  encrypt  the S3 object. Without this key, data in the
                     bucket is not accessible.

              Status -> (string)
                 Indicates the status of the inference execution.

              FailedReason -> (string)
                 Specifies the reason for failure when an inference  execution
                 has failed.



                                                   LIST-INFERENCE-EXECUTIONS()

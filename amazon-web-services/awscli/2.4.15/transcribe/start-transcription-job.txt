START-TRANSCRIPTION-JOB()                            START-TRANSCRIPTION-JOB()



NAME
       start-transcription-job -

DESCRIPTION
       Starts an asynchronous job to transcribe speech to text.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            start-transcription-job
          --transcription-job-name <value>
          [--language-code <value>]
          [--media-sample-rate-hertz <value>]
          [--media-format <value>]
          --media <value>
          [--output-bucket-name <value>]
          [--output-key <value>]
          [--output-encryption-kms-key-id <value>]
          [--kms-encryption-context <value>]
          [--settings <value>]
          [--model-settings <value>]
          [--job-execution-settings <value>]
          [--content-redaction <value>]
          [--identify-language | --no-identify-language]
          [--language-options <value>]
          [--subtitles <value>]
          [--tags <value>]
          [--language-id-settings <value>]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --transcription-job-name (string)
          The  name  of  the  job.  You can't use the strings ". " or ".. " by
          themselves as the job name. The name must also be unique  within  an
          Amazon  Web  Services  account. If you try to create a transcription
          job with the same name as a previous transcription job,  you  get  a
          ConflictException error.

       --language-code (string)
          The language code for the language used in the input media file.

          To  transcribe  speech in Modern Standard Arabic (ar-SA), your audio
          or video file must be encoded at a  sample  rate  of  16,000  Hz  or
          higher.

          Possible values:

          o af-ZA

          o ar-AE

          o ar-SA

          o cy-GB

          o da-DK

          o de-CH

          o de-DE

          o en-AB

          o en-AU

          o en-GB

          o en-IE

          o en-IN

          o en-US

          o en-WL

          o es-ES

          o es-US

          o fa-IR

          o fr-CA

          o fr-FR

          o ga-IE

          o gd-GB

          o he-IL

          o hi-IN

          o id-ID

          o it-IT

          o ja-JP

          o ko-KR

          o ms-MY

          o nl-NL

          o pt-BR

          o pt-PT

          o ru-RU

          o ta-IN

          o te-IN

          o tr-TR

          o zh-CN

          o zh-TW

          o th-TH

          o en-ZA

          o en-NZ

       --media-sample-rate-hertz (integer)
          The  sample  rate,  in  Hertz, of the audio track in the input media
          file.

          If you do not specify  the  media  sample  rate,  Amazon  Transcribe
          determines  the sample rate. If you specify the sample rate, it must
          match the sample rate detected by Amazon Transcribe. In most  cases,
          you should leave the MediaSampleRateHertz field blank and let Amazon
          Transcribe determine the sample rate.

       --media-format (string)
          The format of the input media file.

          Possible values:

          o mp3

          o mp4

          o wav

          o flac

          o ogg

          o amr

          o webm

       --media (structure)
          An object that describes the input media for a transcription job.

          MediaFileUri -> (string)
              The S3 object location of the input media file. The URI must  be
              in the same region as the API endpoint that you are calling. The
              general form is:
                 s3://<AWSDOC-EXAMPLE-BUCKET>/<keyprefix>/<objectkey>

              For example:
                 s3://AWSDOC-EXAMPLE-BUCKET/example.mp4

                 s3://AWSDOC-EXAMPLE-BUCKET/mediadocs/example.mp4

              For more information about S3 object names, see Object  Keys  in
              the Amazon S3 Developer Guide .

          RedactedMediaFileUri -> (string)
              The S3 object location for your redacted output media file. This
              is only supported for call analytics jobs.

       Shorthand Syntax:

          MediaFileUri=string,RedactedMediaFileUri=string

       JSON Syntax:

          {
            "MediaFileUri": "string",
            "RedactedMediaFileUri": "string"
          }

       --output-bucket-name (string)
          The location where the transcription is stored.

          If you set the OutputBucketName , Amazon Transcribe puts  the  tran-
          script  in the specified S3 bucket. When you call the  GetTranscrip-
          tionJob operation, the operation returns this location in the  Tran-
          scriptFileUri  field.  If you enable content redaction, the redacted
          transcript appears in RedactedTranscriptFileUri . If you enable con-
          tent  redaction  and choose to output an unredacted transcript, that
          transcript's location still appears in the TranscriptFileUri  .  The
          S3  bucket must have permissions that allow Amazon Transcribe to put
          files in the bucket. For more information, see Permissions  Required
          for IAM User Roles .

          You  can specify an Amazon Web Services Key Management Service (KMS)
          key to encrypt the output of your transcription using the  OutputEn-
          cryptionKMSKeyId  parameter.  If you don't specify a KMS key, Amazon
          Transcribe uses the default Amazon S3 key for server-side encryption
          of transcripts that are placed in your S3 bucket.

          If  you don't set the OutputBucketName , Amazon Transcribe generates
          a pre-signed URL, a shareable URL that  provides  secure  access  to
          your  transcription,  and returns it in the TranscriptFileUri field.
          Use this URL to download the transcription.

       --output-key (string)
          You can specify a location in an Amazon S3 bucket to store the  out-
          put of your transcription job.

          If  you  don't  specify  an output key, Amazon Transcribe stores the
          output of your transcription job in the Amazon S3 bucket you  speci-
          fied.    By    default,   the   object   key   is   "your-transcrip-
          tion-job-name.json".

          You can use output keys to specify the Amazon  S3  prefix  and  file
          name of the transcription output. For example, specifying the Amazon
          S3 prefix, "folder1/folder2/", as an output key would  lead  to  the
          output     being    stored    as    "folder1/folder2/your-transcrip-
          tion-job-name.json". If you specify "my-other-job-name.json" as  the
          output  key,  the object key is changed to "my-other-job-name.json".
          You can use an output key to change both the  prefix  and  the  file
          name, for example "folder/my-other-job-name.json".

          If  you specify an output key, you must also specify an S3 bucket in
          the OutputBucketName parameter.

       --output-encryption-kms-key-id (string)
          The Amazon Resource Name (ARN) of the Amazon Web Services  Key  Man-
          agement  Service  (KMS)  key used to encrypt the output of the tran-
          scription job. The user calling the StartTranscriptionJob  operation
          must have permission to use the specified KMS key.

          You  can  use  either  of the following to identify a KMS key in the
          current account:

          o KMS Key ID: "1234abcd-12ab-34cd-56ef-1234567890ab"

          o KMS Key Alias: "alias/ExampleAlias"

          You can use either of the following to identify a  KMS  key  in  the
          current account or another account:

          o Amazon     Resource     Name     (ARN)     of     a    KMS    Key:
            "arn:aws:kms:region:account
            ID:key/1234abcd-12ab-34cd-56ef-1234567890ab"

          o ARN of a KMS Key Alias: "arn:aws:kms:region:account-ID:alias/Exam-
            pleAlias"

          If you don't specify an encryption key, the output of the transcrip-
          tion job is encrypted with the default Amazon S3 key (SSE-S3).

          If you specify a KMS key to encrypt your output, you must also spec-
          ify an output location in the OutputBucketName parameter.

       --kms-encryption-context (map)
          A map of plain text, non-secret key:value pairs, known as encryption
          context  pairs,  that  provide  an  added layer of security for your
          data.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --settings (structure)
          A Settings object that provides optional settings for  a  transcrip-
          tion job.

          VocabularyName -> (string)
              The  name  of a vocabulary to use when processing the transcrip-
              tion job.

          ShowSpeakerLabels -> (boolean)
              Determines whether the transcription job uses  speaker  recogni-
              tion  to identify different speakers in the input audio. Speaker
              recognition labels individual speakers in the audio file. If you
              set  the  ShowSpeakerLabels field to true, you must also set the
              maximum number of speaker labels MaxSpeakerLabels field.

              You can't set both ShowSpeakerLabels  and  ChannelIdentification
              in  the  same  request.  If you set both, your request returns a
              BadRequestException .

          MaxSpeakerLabels -> (integer)
              The maximum number of speakers to identify in the  input  audio.
              If there are more speakers in the audio than this number, multi-
              ple speakers are identified as a single speaker. If you  specify
              the  MaxSpeakerLabels  field, you must set the ShowSpeakerLabels
              field to true.

          ChannelIdentification -> (boolean)
              Instructs Amazon Transcribe to process each audio channel  sepa-
              rately  and  then merge the transcription output of each channel
              into a single transcription.

              Amazon Transcribe also produces a  transcription  of  each  item
              detected  on  an audio channel, including the start time and end
              time of the item and  alternative  transcriptions  of  the  item
              including the confidence that Amazon Transcribe has in the tran-
              scription.

              You can't set both ShowSpeakerLabels  and  ChannelIdentification
              in  the  same  request.  If you set both, your request returns a
              BadRequestException .

          ShowAlternatives -> (boolean)
              Determines whether the transcription contains alternative  tran-
              scriptions.  If  you set the ShowAlternatives field to true, you
              must also set the maximum number of alternatives  to  return  in
              the MaxAlternatives field.

          MaxAlternatives -> (integer)
              The number of alternative transcriptions that the service should
              return. If you specify the MaxAlternatives field, you  must  set
              the ShowAlternatives field to true.

          VocabularyFilterName -> (string)
              The  name  of the vocabulary filter to use when transcribing the
              audio. The filter that you specify must have the  same  language
              code as the transcription job.

          VocabularyFilterMethod -> (string)
              Set  to  mask  to  remove  filtered text from the transcript and
              replace it with three asterisks ("
              **

              *
              ") as placeholder text. Set to remove to  remove  filtered  text
              from  the  transcript without using placeholder text. Set to tag
              to mark the word in the transcription output  that  matches  the
              vocabulary  filter.  When you set the filter method to tag , the
              words matching your vocabulary filter are not masked or removed.

       Shorthand Syntax:

          VocabularyName=string,ShowSpeakerLabels=boolean,MaxSpeakerLabels=integer,ChannelIdentification=boolean,ShowAlternatives=boolean,MaxAlternatives=integer,VocabularyFilterName=string,VocabularyFilterMethod=string

       JSON Syntax:

          {
            "VocabularyName": "string",
            "ShowSpeakerLabels": true|false,
            "MaxSpeakerLabels": integer,
            "ChannelIdentification": true|false,
            "ShowAlternatives": true|false,
            "MaxAlternatives": integer,
            "VocabularyFilterName": "string",
            "VocabularyFilterMethod": "remove"|"mask"|"tag"
          }

       --model-settings (structure)
          Choose  the custom language model you use for your transcription job
          in this parameter.

          LanguageModelName -> (string)
              The name of your custom language model.

       Shorthand Syntax:

          LanguageModelName=string

       JSON Syntax:

          {
            "LanguageModelName": "string"
          }

       --job-execution-settings (structure)
          Provides information about how a transcription job is executed.  Use
          this  field to indicate that the job can be queued for deferred exe-
          cution if the concurrency limit is reached and there  are  no  slots
          available to immediately run the job.

          AllowDeferredExecution -> (boolean)
              Indicates  whether  a  job should be queued by Amazon Transcribe
              when the  concurrent  execution  limit  is  exceeded.  When  the
              AllowDeferredExecution  field  is true, jobs are queued and exe-
              cuted when the number of executing jobs falls below the  concur-
              rent  execution  limit. If the field is false, Amazon Transcribe
              returns a LimitExceededException exception.

              Note that job queuing is enabled by default for  call  analytics
              jobs.

              If  you specify the AllowDeferredExecution field, you must spec-
              ify the DataAccessRoleArn field.

          DataAccessRoleArn -> (string)
              The Amazon Resource Name (ARN), in the  form  arn:partition:ser-
              vice:region:account-id:resource-type/resource-id  ,  of  a  role
              that has access to the S3 bucket that contains the input  files.
              Amazon  Transcribe assumes this role to read queued media files.
              If you have specified an output S3 bucket for the  transcription
              results,  this  role  should have access to the output bucket as
              well.

              If you specify the AllowDeferredExecution field, you must  spec-
              ify the DataAccessRoleArn field.

       Shorthand Syntax:

          AllowDeferredExecution=boolean,DataAccessRoleArn=string

       JSON Syntax:

          {
            "AllowDeferredExecution": true|false,
            "DataAccessRoleArn": "string"
          }

       --content-redaction (structure)
          An  object  that  contains the request parameters for content redac-
          tion.

          RedactionType -> (string)
              Request parameter that defines the entities to be redacted.  The
              only accepted value is PII .

          RedactionOutput -> (string)
              The  output  transcript  file  stored  in  either the default S3
              bucket or in a bucket you specify.

              When you choose redacted  Amazon  Transcribe  outputs  only  the
              redacted transcript.

              When  you  choose redacted_and_unredacted Amazon Transcribe out-
              puts both the redacted and unredacted transcripts.

          PiiEntityTypes -> (list)
              The types of personally identifiable information (PII) you  want
              to redact in your transcript.

              (string)

       Shorthand Syntax:

          RedactionType=string,RedactionOutput=string,PiiEntityTypes=string,string

       JSON Syntax:

          {
            "RedactionType": "PII",
            "RedactionOutput": "redacted"|"redacted_and_unredacted",
            "PiiEntityTypes": ["BANK_ACCOUNT_NUMBER"|"BANK_ROUTING"|"CREDIT_DEBIT_NUMBER"|"CREDIT_DEBIT_CVV"|"CREDIT_DEBIT_EXPIRY"|"PIN"|"EMAIL"|"ADDRESS"|"NAME"|"PHONE"|"SSN"|"ALL", ...]
          }

       --identify-language | --no-identify-language (boolean)
          Set  this field to true to enable automatic language identification.
          Automatic  language  identification  is  disabled  by  default.  You
          receive  a BadRequestException error if you enter a value for a Lan-
          guageCode .

       --language-options (list)
          An object containing a list of languages that might  be  present  in
          your  collection  of  audio files. Automatic language identification
          chooses a language that best matches  the  source  audio  from  that
          list.

          To  transcribe  speech in Modern Standard Arabic (ar-SA), your audio
          or video file must be encoded at a  sample  rate  of  16,000  Hz  or
          higher.

          (string)

       Syntax:

          "string" "string" ...

          Where valid values are:
            af-ZA
            ar-AE
            ar-SA
            cy-GB
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            ga-IE
            gd-GB
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ

       --subtitles (structure)
          Add subtitles to your batch transcription job.

          Formats -> (list)
              Specify the output format for your subtitle file.

              (string)

       Shorthand Syntax:

          Formats=string,string

       JSON Syntax:

          {
            "Formats": ["vtt"|"srt", ...]
          }

       --tags (list)
          Add tags to an Amazon Transcribe transcription job.

          (structure)
              A key:value pair that adds metadata to a resource used by Amazon
              Transcribe. For example, a tag with the key:value  pair  Depart-
              ment:Sales  might  be added to a resource to indicate its use by
              your organization's sales department.

              Key -> (string)
                 The first part of a key:value pair that forms a  tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales, the key is 'Department'.

              Value -> (string)
                 The second part of a key:value pair that forms a tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales, the value is 'Sales'.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --language-id-settings (map)
          The language identification settings associated with your transcrip-
          tion  job. These settings include VocabularyName , VocabularyFilter-
          Name , and LanguageModelName .

          key -> (string)

          value -> (structure)
              Language-specific settings that can be specified  when  language
              identification is enabled.

              VocabularyName -> (string)
                 The  name  of  the vocabulary you want to use when processing
                 your transcription job. The vocabulary you specify must  have
                 the same language codes as the transcription job; if the lan-
                 guages don't match, the vocabulary isn't applied.

              VocabularyFilterName -> (string)
                 The name of the vocabulary filter you want to use when  tran-
                 scribing  your  audio.  The  filter you specify must have the
                 same language codes as the transcription  job;  if  the  lan-
                 guages don't match, the vocabulary filter isn't be applied.

              LanguageModelName -> (string)
                 The  name  of  the  language model you want to use when tran-
                 scribing your audio. The model you specify must have the same
                 language  codes  as  the  transcription job; if the languages
                 don't match, the language model isn't be applied.

       Shorthand Syntax:

            KeyName1=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string,KeyName2=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string

          Where valid key names are:
            af-ZA
            ar-AE
            ar-SA
            cy-GB
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            ga-IE
            gd-GB
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ

       JSON Syntax:

          {"af-ZA"|"ar-AE"|"ar-SA"|"cy-GB"|"da-DK"|"de-CH"|"de-DE"|"en-AB"|"en-AU"|"en-GB"|"en-IE"|"en-IN"|"en-US"|"en-WL"|"es-ES"|"es-US"|"fa-IR"|"fr-CA"|"fr-FR"|"ga-IE"|"gd-GB"|"he-IL"|"hi-IN"|"id-ID"|"it-IT"|"ja-JP"|"ko-KR"|"ms-MY"|"nl-NL"|"pt-BR"|"pt-PT"|"ru-RU"|"ta-IN"|"te-IN"|"tr-TR"|"zh-CN"|"zh-TW"|"th-TH"|"en-ZA"|"en-NZ": {
                "VocabularyName": "string",
                "VocabularyFilterName": "string",
                "LanguageModelName": "string"
              }
            ...}

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

EXAMPLES
       Example 1: To transcribe an audio file

       The following start-transcription-job example  transcribes  your  audio
       file.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfile.json

       Contents of myfile.json:

          {
              "TranscriptionJobName": "cli-simple-transcription-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       For  more information, see Getting Started (AWS Command Line Interface)
       in the Amazon Transcribe Developer Guide.

       Example 2: To transcribe a multi-channel audio file

       The  following   start-transcription-job   example   transcribes   your
       multi-channel audio file.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysecondfile.json

       Contents of mysecondfile.json:

          {
              "TranscriptionJobName": "cli-channelid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "ChannelIdentification":true
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-channelid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:07:56.817000+00:00",
                  "CreationTime": "2020-09-17T16:07:56.784000+00:00",
                  "Settings": {
                      "ChannelIdentification": true
                  }
              }
          }

       For  more information, see Transcribing Multi-Channel Audio in the Ama-
       zon Transcribe Developer Guide.

       Example 3: To transcribe an  audio  file  and  identify  the  different
       speakers

       The  following  start-transcription-job  example transcribes your audio
       file and identifies the speakers in the transcription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://mythirdfile.json

       Contents of mythirdfile.json:

          {
              "TranscriptionJobName": "cli-speakerid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
              "ShowSpeakerLabels": true,
              "MaxSpeakerLabels": 2
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-speakerid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:22:59.696000+00:00",
                  "CreationTime": "2020-09-17T16:22:59.676000+00:00",
                  "Settings": {
                      "ShowSpeakerLabels": true,
                      "MaxSpeakerLabels": 2
                  }
              }
          }

       For more information, see Identifying Speakers in the Amazon Transcribe
       Developer Guide.

       Example  4:  To transcribe an audio file and mask any unwanted words in
       the transcription output

       The following start-transcription-job example  transcribes  your  audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfourthfile.json

       Contents of myfourthfile.json:

          {
              "TranscriptionJobName": "cli-filter-mask-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                    "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "mask"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-mask-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "mask"
                  }
              }
          }

       For more information, see Filtering Transcriptions in the Amazon  Tran-
       scribe Developer Guide.

       Example 5: To transcribe an audio file and remove any unwanted words in
       the transcription output

       The following start-transcription-job example  transcribes  your  audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfifthfile.json

       Contents of myfifthfile.json:

          {
              "TranscriptionJobName": "cli-filter-remove-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "remove"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-remove-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "remove"
                  }
              }
          }

       For more information, see Filtering Transcriptions in the Amazon  Tran-
       scribe Developer Guide.

       Example  6: To transcribe an audio file with increased accuracy using a
       custom vocabulary

       The following start-transcription-job example  transcribes  your  audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysixthfile.json

       Contents of mysixthfile.json:

          {
              "TranscriptionJobName": "cli-vocab-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyName": "your-vocabulary"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-vocab-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyName": "your-vocabulary"
                  }
              }
          }

       For more information, see Filtering Transcriptions in the Amazon  Tran-
       scribe Developer Guide.

       Example 7: To identify the language of an audio file and transcribe it

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myseventhfile.json

       Contents of myseventhfile.json:

          {
              "TranscriptionJobName": "cli-identify-language-transcription-job",
              "IdentifyLanguage": true,
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-identify-language-transcription-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T22:27:23.970000+00:00",
                  "CreationTime": "2020-09-18T22:27:23.948000+00:00",
                  "IdentifyLanguage": true
              }
          }

       For  more information, see Identifying the Language in the Amazon Tran-
       scribe Developer Guide.

       Example 8: To transcribe an audio  file  with  personally  identifiable
       information redacted

       The  following  start-transcription-job  example transcribes your audio
       file and redacts any personally identifiable information in  the  tran-
       scription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://myeighthfile.json

       Contents of myeigthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
              },
              "ContentRedaction": {
                  "RedactionOutput":"redacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:49:13.195000+00:00",
                  "CreationTime": "2020-09-25T23:49:13.176000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted"
                  }
              }
          }

       For  more  information,  see  Automatic Content Redaction in the Amazon
       Transcribe Developer Guide.

       Example 9: To generate a transcript with personally identifiable infor-
       mation (PII) redacted and an unredacted transcript

       The  following  start-transcription-job example generates two transcrp-
       tions of your audio file, one with the personally identifiable informa-
       tion redacted, and the other without any redactions.

          aws transcribe start-transcription-job \
              --cli-input-json file://myninthfile.json

       Contents of myninthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
              "LanguageCode": "language-code",
              "Media": {
                    "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
              "ContentRedaction": {
                  "RedactionOutput":"redacted_and_unredacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:59:47.677000+00:00",
                  "CreationTime": "2020-09-25T23:59:47.653000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted_and_unredacted"
                  }
              }
          }

       For  more  information,  see  Automatic Content Redaction in the Amazon
       Transcribe Developer Guide.

       Example 10: To use a custom language model you've previously created to
       transcribe an audio file.

       The  following  start-transcription-job  example transcribes your audio
       file with a custom language model you've previously created.

          aws transcribe start-transcription-job \
              --cli-input-json file://mytenthfile.json

       Contents of mytenthfile.json:

          {
              "TranscriptionJobName": "cli-clm-2-job-1",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
              },
              "ModelSettings": {
                  "LanguageModelName":"cli-clm-2"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-clm-2-job-1",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
                  },
                  "StartTime": "2020-09-28T17:56:01.835000+00:00",
                  "CreationTime": "2020-09-28T17:56:01.801000+00:00",
                  "ModelSettings": {
                      "LanguageModelName": "cli-clm-2"
                  }
              }
          }

       For more information, see Improving Domain-Specific Transcription Accu-
       racy  with  Custom  Language  Models in the Amazon Transcribe Developer
       Guide.

OUTPUT
       TranscriptionJob -> (structure)
          An object containing details of the asynchronous transcription  job.

          TranscriptionJobName -> (string)
              The name of the transcription job.

          TranscriptionJobStatus -> (string)
              The status of the transcription job.

          LanguageCode -> (string)
              The language code for the input speech.

          MediaSampleRateHertz -> (integer)
              The  sample rate, in Hertz (Hz), of the audio track in the input
              media file.

          MediaFormat -> (string)
              The format of the input media file.

          Media -> (structure)
              An object that describes the input media for  the  transcription
              job.

              MediaFileUri -> (string)
                 The  S3 object location of the input media file. The URI must
                 be in the same region as the API endpoint that you are  call-
                 ing. The general form is:
                     s3://<AWSDOC-EXAMPLE-BUCKET>/<keyprefix>/<objectkey>

                 For example:
                     s3://AWSDOC-EXAMPLE-BUCKET/example.mp4

                     s3://AWSDOC-EXAMPLE-BUCKET/mediadocs/example.mp4

                 For  more  information about S3 object names, see Object Keys
                 in the Amazon S3 Developer Guide .

              RedactedMediaFileUri -> (string)
                 The S3 object location for your redacted output  media  file.
                 This is only supported for call analytics jobs.

          Transcript -> (structure)
              An object that describes the output of the transcription job.

              TranscriptFileUri -> (string)
                 The S3 object location of the transcript.

                 Use this URI to access the transcript. If you specified an S3
                 bucket in the OutputBucketName field  when  you  created  the
                 job,  this  is  the URI of that bucket. If you chose to store
                 the transcript in Amazon Transcribe, this is a shareable  URL
                 that provides secure access to that location.

              RedactedTranscriptFileUri -> (string)
                 The S3 object location of the redacted transcript.

                 Use this URI to access the redacted transcript. If you speci-
                 fied an S3 bucket in the OutputBucketName field when you cre-
                 ated the job, this is the URI of that bucket. If you chose to
                 store the transcript in Amazon Transcribe, this is  a  share-
                 able URL that provides secure access to that location.

          StartTime -> (timestamp)
              A timestamp that shows when the job started processing.

          CreationTime -> (timestamp)
              A timestamp that shows when the job was created.

          CompletionTime -> (timestamp)
              A timestamp that shows when the job completed.

          FailureReason -> (string)
              If  the TranscriptionJobStatus field is FAILED , this field con-
              tains information about why the job failed.

              The FailureReason field can contain one of the following values:

              o Unsupported  media  format - The media format specified in the
                MediaFormat field of the request isn't valid. See the descrip-
                tion of the MediaFormat field for a list of valid values.

              o The  media  format  provided does not match the detected media
                format - The media format of the audio file doesn't match  the
                format  specified  in  the  MediaFormat  field in the request.
                Check the media format of your media file and make  sure  that
                the two values match.

              o Invalid sample rate for audio file - The sample rate specified
                in the MediaSampleRateHertz of the request  isn't  valid.  The
                sample rate must be between 8,000 and 48,000 Hertz.

              o The  sample  rate  provided does not match the detected sample
                rate - The sample rate in the audio  file  doesn't  match  the
                sample rate specified in the MediaSampleRateHertz field in the
                request. Check the sample rate of your  media  file  and  make
                sure that the two values match.

              o Invalid  file  size:  file  size  too large - The size of your
                audio file is larger than Amazon Transcribe can  process.  For
                more  information,  see Limits in the Amazon Transcribe Devel-
                oper Guide .

              o Invalid number of channels: number of  channels  too  large  -
                Your  audio  contains  more channels than Amazon Transcribe is
                configured to process. To  request  additional  channels,  see
                Amazon  Transcribe  Limits  in the Amazon Web Services General
                Reference .

          Settings -> (structure)
              Optional settings for the transcription job. Use these  settings
              to  turn  on  speaker  recognition, to set the maximum number of
              speakers that should be  identified  and  to  specify  a  custom
              vocabulary to use when processing the transcription job.

              VocabularyName -> (string)
                 The  name  of  a  vocabulary to use when processing the tran-
                 scription job.

              ShowSpeakerLabels -> (boolean)
                 Determines whether the transcription job uses speaker  recog-
                 nition  to  identify  different  speakers in the input audio.
                 Speaker recognition labels individual speakers in  the  audio
                 file.  If  you  set  the ShowSpeakerLabels field to true, you
                 must also set the maximum number of speaker labels  MaxSpeak-
                 erLabels field.

                 You  can't  set both ShowSpeakerLabels and ChannelIdentifica-
                 tion in the same request.  If  you  set  both,  your  request
                 returns a BadRequestException .

              MaxSpeakerLabels -> (integer)
                 The  maximum  number  of  speakers  to  identify in the input
                 audio. If there are more speakers in the audio than this num-
                 ber, multiple speakers are identified as a single speaker. If
                 you specify the MaxSpeakerLabels  field,  you  must  set  the
                 ShowSpeakerLabels field to true.

              ChannelIdentification -> (boolean)
                 Instructs  Amazon  Transcribe  to  process each audio channel
                 separately and then merge the transcription  output  of  each
                 channel into a single transcription.

                 Amazon  Transcribe also produces a transcription of each item
                 detected on an audio channel, including the  start  time  and
                 end  time  of  the item and alternative transcriptions of the
                 item including the confidence that Amazon Transcribe  has  in
                 the transcription.

                 You  can't  set both ShowSpeakerLabels and ChannelIdentifica-
                 tion in the same request.  If  you  set  both,  your  request
                 returns a BadRequestException .

              ShowAlternatives -> (boolean)
                 Determines  whether  the  transcription  contains alternative
                 transcriptions. If you  set  the  ShowAlternatives  field  to
                 true, you must also set the maximum number of alternatives to
                 return in the MaxAlternatives field.

              MaxAlternatives -> (integer)
                 The number of alternative  transcriptions  that  the  service
                 should  return. If you specify the MaxAlternatives field, you
                 must set the ShowAlternatives field to true.

              VocabularyFilterName -> (string)
                 The name of the vocabulary filter to  use  when  transcribing
                 the  audio.  The  filter  that you specify must have the same
                 language code as the transcription job.

              VocabularyFilterMethod -> (string)
                 Set to mask to remove filtered text from the  transcript  and
                 replace it with three asterisks ("
                 **

                 *
                 ") as placeholder text. Set to remove to remove filtered text
                 from the transcript without using placeholder  text.  Set  to
                 tag to mark the word in the transcription output that matches
                 the vocabulary filter. When you set the filter method to  tag
                 , the words matching your vocabulary filter are not masked or
                 removed.

          ModelSettings -> (structure)
              An object containing the details of your custom language  model.

              LanguageModelName -> (string)
                 The name of your custom language model.

          JobExecutionSettings -> (structure)
              Provides  information about how a transcription job is executed.

              AllowDeferredExecution -> (boolean)
                 Indicates whether a job should be queued by Amazon Transcribe
                 when  the  concurrent  execution  limit is exceeded. When the
                 AllowDeferredExecution field is true,  jobs  are  queued  and
                 executed  when  the  number of executing jobs falls below the
                 concurrent execution limit. If the  field  is  false,  Amazon
                 Transcribe returns a LimitExceededException exception.

                 Note  that job queuing is enabled by default for call analyt-
                 ics jobs.

                 If you specify the  AllowDeferredExecution  field,  you  must
                 specify the DataAccessRoleArn field.

              DataAccessRoleArn -> (string)
                 The  Amazon  Resource  Name  (ARN),  in  the  form arn:parti-
                 tion:service:region:account-id:resource-type/resource-id , of
                 a  role  that  has  access to the S3 bucket that contains the
                 input files. Amazon Transcribe  assumes  this  role  to  read
                 queued media files. If you have specified an output S3 bucket
                 for the transcription results, this role should  have  access
                 to the output bucket as well.

                 If  you  specify  the  AllowDeferredExecution field, you must
                 specify the DataAccessRoleArn field.

          ContentRedaction -> (structure)
              An object that describes  content  redaction  settings  for  the
              transcription job.

              RedactionType -> (string)
                 Request  parameter  that defines the entities to be redacted.
                 The only accepted value is PII .

              RedactionOutput -> (string)
                 The output transcript file stored in either  the  default  S3
                 bucket or in a bucket you specify.

                 When  you  choose redacted Amazon Transcribe outputs only the
                 redacted transcript.

                 When you  choose  redacted_and_unredacted  Amazon  Transcribe
                 outputs both the redacted and unredacted transcripts.

              PiiEntityTypes -> (list)
                 The  types  of  personally identifiable information (PII) you
                 want to redact in your transcript.

                 (string)

          IdentifyLanguage -> (boolean)
              A value that shows  if  automatic  language  identification  was
              enabled for a transcription job.

          LanguageOptions -> (list)
              An  object  that  shows the optional array of languages inputted
              for transcription jobs with  automatic  language  identification
              enabled.

              (string)

          IdentifiedLanguageScore -> (float)
              A  value between zero and one that Amazon Transcribe assigned to
              the language that it identified in the source audio. Larger val-
              ues indicate that Amazon Transcribe has higher confidence in the
              language it identified.

          Tags -> (list)
              A key:value pair assigned to a given transcription job.

              (structure)
                 A key:value pair that adds metadata to  a  resource  used  by
                 Amazon Transcribe. For example, a tag with the key:value pair
                 Department:Sales might be added to a resource to indicate its
                 use by your organization's sales department.

                 Key -> (string)
                     The first part of a key:value pair that forms a tag asso-
                     ciated with a given resource. For  example,  in  the  tag
                     Department:Sales, the key is 'Department'.

                 Value -> (string)
                     The  second  part  of  a  key:value pair that forms a tag
                     associated with a given resource. For example, in the tag
                     Department:Sales, the value is 'Sales'.

          Subtitles -> (structure)
              Generate subtitles for your batch transcription job.

              Formats -> (list)
                 Specify  the  output  format  for  your subtitle file; if you
                 select both SRT and VTT formats, two output files are  gener-
                 ated.

                 (string)

              SubtitleFileUris -> (list)
                 Choose the output location for your subtitle file. This loca-
                 tion must be an S3 bucket.

                 (string)

          LanguageIdSettings -> (map)
              Language-specific settings that can be specified  when  language
              identification is enabled for your transcription job. These set-
              tings include VocabularyName , VocabularyFilterName ,  and  Lan-
              guageModelName .

              key -> (string)

              value -> (structure)
                 Language-specific  settings  that  can be specified when lan-
                 guage identification is enabled.

                 VocabularyName -> (string)
                     The name of the vocabulary you want to use when  process-
                     ing  your  transcription  job. The vocabulary you specify
                     must have the same language codes  as  the  transcription
                     job;  if  the languages don't match, the vocabulary isn't
                     applied.

                 VocabularyFilterName -> (string)
                     The name of the vocabulary filter you want  to  use  when
                     transcribing your audio. The filter you specify must have
                     the same language codes as the transcription job; if  the
                     languages  don't  match,  the  vocabulary filter isn't be
                     applied.

                 LanguageModelName -> (string)
                     The name of the language model you want to use when tran-
                     scribing  your audio. The model you specify must have the
                     same language codes as the transcription job; if the lan-
                     guages  don't match, the language model isn't be applied.



                                                     START-TRANSCRIPTION-JOB()

CREATE-DATA-SOURCE-FROM-S3()                      CREATE-DATA-SOURCE-FROM-S3()



NAME
       create-data-source-from-s3 -

DESCRIPTION
       Creates  a  DataSource object. A DataSource references data that can be
       used to perform CreateMLModel , CreateEvaluation ,  or  CreateBatchPre-
       diction operations.
          CreateDataSourceFromS3  is an asynchronous operation. In response to
          CreateDataSourceFromS3 , Amazon Machine Learning (Amazon ML) immedi-
          ately  returns and sets the DataSource status to PENDING . After the
          DataSource has been created and is ready for use, Amazon ML sets the
          Status parameter to COMPLETED . DataSource in the COMPLETED or PEND-
          ING state can be used to perform only CreateMLModel ,  CreateEvalua-
          tion or CreateBatchPrediction operations.

       If  Amazon ML can't accept the input source, it sets the Status parame-
       ter to FAILED and includes an error message in the Message attribute of
       the GetDataSource operation response.

       The  observation data used in a DataSource should be ready to use; that
       is, it should have a consistent  structure,  and  missing  data  values
       should be kept to a minimum. The observation data must reside in one or
       more .csv files in an Amazon Simple Storage Service (Amazon  S3)  loca-
       tion,  along  with  a  schema that describes the data items by name and
       type. The same schema must be used for all of the data files referenced
       by the DataSource .

       After the DataSource has been created, it's ready to use in evaluations
       and batch predictions. If you plan to use the DataSource  to  train  an
       MLModel  ,  the  DataSource also needs a recipe. A recipe describes how
       each input variable will be used in training  an  MLModel  .  Will  the
       variable  be  included  or excluded from training? Will the variable be
       manipulated; for example, will it be combined with another variable  or
       will  it  be  split  apart  into word combinations? The recipe provides
       answers to these questions.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-data-source-from-s3
          --data-source-id <value>
          [--data-source-name <value>]
          --data-spec <value>
          [--compute-statistics | --no-compute-statistics]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --data-source-id (string)
          A user-supplied identifier that uniquely identifies the DataSource .

       --data-source-name (string)
          A user-supplied name or description of the DataSource .

       --data-spec (structure)
          The data specification of a DataSource :

          o DataLocationS3 - The Amazon S3 location of the observation data.

          o DataSchemaLocationS3  - The Amazon S3 location of the DataSchema .

          o DataSchema - A JSON string representing the schema.  This  is  not
            required if DataSchemaUri is specified.

          o DataRearrangement  -  A  JSON string that represents the splitting
            and rearrangement requirements for  the  Datasource  .   Sample  -
            "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"

          DataLocationS3 -> (string)
              The  location of the data file(s) used by a DataSource . The URI
              specifies a data file or an Amazon Simple Storage Service  (Ama-
              zon S3) directory or bucket containing data files.

          DataRearrangement -> (string)
              A  JSON  string  that represents the splitting and rearrangement
              processing to be applied to a DataSource . If the DataRearrange-
              ment parameter is not provided, all of the input data is used to
              create the Datasource .

              There are multiple parameters that control what data is used  to
              create a datasource:

              o
                **
                percentBegin  **    Use percentBegin to indicate the beginning
                of the range of the data used to create the Datasource. If you
                do  not  include  percentBegin  and  percentEnd  ,  Amazon  ML
                includes all of the data when creating the datasource.

              o
                **
                percentEnd **   Use percentEnd to  indicate  the  end  of  the
                range of the data used to create the Datasource. If you do not
                include percentBegin and percentEnd , Amazon ML  includes  all
                of the data when creating the datasource.

              o
                **
                complement  **    The complement parameter instructs Amazon ML
                to use the data that is not included in the range of  percent-
                Begin  to  percentEnd  to  create a datasource. The complement
                parameter is useful if you need to create complementary  data-
                sources for training and evaluation. To create a complementary
                datasource, use the same  values  for  percentBegin  and  per-
                centEnd  ,  along  with the complement parameter. For example,
                the following two datasources do not share any data,  and  can
                be  used  to  train and evaluate a model. The first datasource
                has 25 percent of the data, and the second one has 75  percent
                of  the  data.  Datasource for evaluation: {"splitting":{"per-
                centBegin":0,  "percentEnd":25}}    Datasource  for  training:
                {"splitting":{"percentBegin":0,    "percentEnd":25,   "comple-
                ment":"true"}}

              o
                **
                strategy **   To change how Amazon ML splits the  data  for  a
                datasource,  use the strategy parameter. The default value for
                the strategy parameter is sequential , meaning that Amazon  ML
                takes  all  of  the  data records between the percentBegin and
                percentEnd parameters for the datasource, in  the  order  that
                the  records  appear  in  the  input  data.  The following two
                DataRearrangement lines are examples of  sequentially  ordered
                training  and  evaluation  datasources: Datasource for evalua-
                tion:    {"splitting":{"percentBegin":70,    "percentEnd":100,
                "strategy":"sequential"}}    Datasource for training: {"split-
                ting":{"percentBegin":70,      "percentEnd":100,       "strat-
                egy":"sequential",  "complement":"true"}}    To randomly split
                the input data into the proportions indicated by the  percent-
                Begin and percentEnd parameters, set the strategy parameter to
                random and provide a string that is used as the seed value for
                the  random  data  splitting  (for example, you can use the S3
                path to your data as the random seed string).  If  you  choose
                the  random split strategy, Amazon ML assigns each row of data
                a pseudo-random number between 0 and 100, and then selects the
                rows  that  have  an  assigned number between percentBegin and
                percentEnd . Pseudo-random numbers are assigned using both the
                input  seed  string  value  and  the byte offset as a seed, so
                changing the data results in a different split.  Any  existing
                ordering  is  preserved. The random splitting strategy ensures
                that variables in the training and evaluation  data  are  dis-
                tributed  similarly. It is useful in the cases where the input
                data may have an implicit sort order,  which  would  otherwise
                result  in  training  and  evaluation  datasources  containing
                non-similar data records. The following two  DataRearrangement
                lines  are  examples  of non-sequentially ordered training and
                evaluation datasources: Datasource  for  evaluation:  {"split-
                ting":{"percentBegin":70,  "percentEnd":100,  "strategy":"ran-
                dom", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}   Data-
                source  for  training:  {"splitting":{"percentBegin":70, "per-
                centEnd":100,          "strategy":"random",           "random-
                Seed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}

          DataSchema -> (string)
              A JSON string that represents the schema for an Amazon S3  Data-
              Source . The DataSchema defines the structure of the observation
              data in the data file(s) referenced in the DataSource .

              You must provide either the DataSchema  or  the  DataSchemaLoca-
              tionS3 .

              Define   your   DataSchema  as  a  series  of  key-value  pairs.
              attributes and excludedVariableNames have an array of  key-value
              pairs  for  their value. Use the following format to define your
              DataSchema .

              { "version": "1.0",

              "recordAnnotationFieldName": "F1",

              "recordWeightFieldName": "F2",

              "targetFieldName": "F3",

              "dataFormat": "CSV",

              "dataFileContainsHeader": true,

              "attributes": [

              { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2",
              "fieldType":  "NUMERIC"  },  {  "fieldName":  "F3", "fieldType":
              "CATEGORICAL" }, { "fieldName": "F4", "fieldType": "NUMERIC"  },
              {  "fieldName":  "F5",  "fieldType":  "CATEGORICAL" }, { "field-
              Name": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "field-
              Type":  "WEIGHTED_INT_SEQUENCE"  }, { "fieldName": "F8", "field-
              Type": "WEIGHTED_STRING_SEQUENCE" } ],

              "excludedVariableNames": [ "F6" ] }

          DataSchemaLocationS3 -> (string)
              Describes the schema location in Amazon  S3.  You  must  provide
              either the DataSchema or the DataSchemaLocationS3 .

       Shorthand Syntax:

          DataLocationS3=string,DataRearrangement=string,DataSchema=string,DataSchemaLocationS3=string

       JSON Syntax:

          {
            "DataLocationS3": "string",
            "DataRearrangement": "string",
            "DataSchema": "string",
            "DataSchemaLocationS3": "string"
          }

       --compute-statistics | --no-compute-statistics (boolean)
          The  compute statistics for a DataSource . The statistics are gener-
          ated from the observation data referenced by a DataSource  .  Amazon
          ML  uses  the  statistics  internally  during MLModel training. This
          parameter must be set to true if the DataSourceneeds to be used  for
          MLModel training.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       DataSourceId -> (string)
          A  user-supplied  ID  that uniquely identifies the DataSource . This
          value should be identical to the value of the  DataSourceID  in  the
          request.



                                                  CREATE-DATA-SOURCE-FROM-S3()

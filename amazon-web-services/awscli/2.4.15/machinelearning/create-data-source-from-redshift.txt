CREATE-DATA-SOURCE-FROM-REDSHIFT()          CREATE-DATA-SOURCE-FROM-REDSHIFT()



NAME
       create-data-source-from-redshift -

DESCRIPTION
       Creates a DataSource from a database hosted on an Amazon Redshift clus-
       ter. A DataSource references data that can be used  to  perform  either
       CreateMLModel , CreateEvaluation , or CreateBatchPrediction operations.
          CreateDataSourceFromRedshift  is  an  asynchronous   operation.   In
          response  to  CreateDataSourceFromRedshift , Amazon Machine Learning
          (Amazon ML) immediately returns and sets the  DataSource  status  to
          PENDING  . After the DataSource is created and ready for use, Amazon
          ML sets the Status parameter to COMPLETED . DataSource in  COMPLETED
          or  PENDING  states can be used to perform only CreateMLModel , Cre-
          ateEvaluation , or CreateBatchPrediction operations.

       If Amazon ML can't accept the input source, it sets the Status  parame-
       ter to FAILED and includes an error message in the Message attribute of
       the GetDataSource operation response.

       The observations should be contained in the database hosted on an  Ama-
       zon Redshift cluster and should be specified by a SelectSqlQuery query.
       Amazon ML executes an Unload command in Amazon Redshift to transfer the
       result set of the SelectSqlQuery query to S3StagingLocation .

       After  the  DataSource  has been created, it's ready for use in evalua-
       tions and batch predictions. If you plan to use the DataSource to train
       an  MLModel , the DataSource also requires a recipe. A recipe describes
       how each input variable will be used in training an MLModel . Will  the
       variable  be  included  or excluded from training? Will the variable be
       manipulated; for example, will it be combined with another variable  or
       will  it  be  split  apart  into word combinations? The recipe provides
       answers to these questions.

       You can't change an existing datasource, but you can  copy  and  modify
       the  settings  from  an existing Amazon Redshift datasource to create a
       new datasource. To do so, call GetDataSource for an existing datasource
       and  copy  the  values  to a CreateDataSource call. Change the settings
       that you want to change and make sure that all required fields have the
       appropriate values.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-data-source-from-redshift
          --data-source-id <value>
          [--data-source-name <value>]
          --data-spec <value>
          --role-arn <value>
          [--compute-statistics | --no-compute-statistics]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --data-source-id (string)
          A user-supplied ID that uniquely identifies the DataSource .

       --data-source-name (string)
          A user-supplied name or description of the DataSource .

       --data-spec (structure)
          The data specification of an Amazon Redshift DataSource :

          o DatabaseInformation -

            o DatabaseName - The name of the Amazon Redshift database.

            o ClusterIdentifier  - The unique ID for the Amazon Redshift clus-
              ter.

          o DatabaseCredentials - The AWS Identity and Access Management (IAM)
            credentials  that are used to connect to the Amazon Redshift data-
            base.

          o SelectSqlQuery - The query that is used to retrieve  the  observa-
            tion data for the Datasource .

          o S3StagingLocation  - The Amazon Simple Storage Service (Amazon S3)
            location for staging Amazon Redshift data. The data retrieved from
            Amazon  Redshift  using the SelectSqlQuery query is stored in this
            location.

          o DataSchemaUri - The Amazon S3 location of the DataSchema .

          o DataSchema - A JSON string representing the schema.  This  is  not
            required if DataSchemaUri is specified.

          o DataRearrangement  -  A  JSON string that represents the splitting
            and rearrangement requirements  for  the  DataSource  .  Sample  -
            "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"

          DatabaseInformation -> (structure)
              Describes  the  DatabaseName and ClusterIdentifier for an Amazon
              Redshift DataSource .

              DatabaseName -> (string)
                 The name of a database hosted on an Amazon Redshift  cluster.

              ClusterIdentifier -> (string)
                 The ID of an Amazon Redshift cluster.

          SelectSqlQuery -> (string)
              Describes  the  SQL Query to execute on an Amazon Redshift data-
              base for an Amazon Redshift DataSource .

          DatabaseCredentials -> (structure)
              Describes AWS Identity and Access Management  (IAM)  credentials
              that are used connect to the Amazon Redshift database.

              Username -> (string)
                 A  username  to  be  used  by Amazon Machine Learning (Amazon
                 ML)to connect to a database on an  Amazon  Redshift  cluster.
                 The  username  should  have sufficient permissions to execute
                 the RedshiftSelectSqlQuery  query.  The  username  should  be
                 valid for an Amazon Redshift USER .

              Password -> (string)
                 A  password  to be used by Amazon ML to connect to a database
                 on an Amazon Redshift cluster. The password should have  suf-
                 ficient   permissions  to  execute  a  RedshiftSelectSqlQuery
                 query. The password should be valid for  an  Amazon  Redshift
                 USER .

          S3StagingLocation -> (string)
              Describes  an  Amazon S3 location to store the result set of the
              SelectSqlQuery query.

          DataRearrangement -> (string)
              A JSON string that represents the  splitting  and  rearrangement
              processing to be applied to a DataSource . If the DataRearrange-
              ment parameter is not provided, all of the input data is used to
              create the Datasource .

              There  are multiple parameters that control what data is used to
              create a datasource:

              o
                **
                percentBegin **   Use percentBegin to indicate  the  beginning
                of the range of the data used to create the Datasource. If you
                do  not  include  percentBegin  and  percentEnd  ,  Amazon  ML
                includes all of the data when creating the datasource.

              o
                **
                percentEnd  **    Use  percentEnd  to  indicate the end of the
                range of the data used to create the Datasource. If you do not
                include  percentBegin  and percentEnd , Amazon ML includes all
                of the data when creating the datasource.

              o
                **
                complement **   The complement parameter instructs  Amazon  ML
                to  use the data that is not included in the range of percent-
                Begin to percentEnd to create  a  datasource.  The  complement
                parameter  is useful if you need to create complementary data-
                sources for training and evaluation. To create a complementary
                datasource,  use  the  same  values  for percentBegin and per-
                centEnd , along with the complement  parameter.  For  example,
                the  following  two datasources do not share any data, and can
                be used to train and evaluate a model.  The  first  datasource
                has  25 percent of the data, and the second one has 75 percent
                of the data. Datasource  for  evaluation:  {"splitting":{"per-
                centBegin":0,  "percentEnd":25}}    Datasource  for  training:
                {"splitting":{"percentBegin":0,   "percentEnd":25,    "comple-
                ment":"true"}}

              o
                **
                strategy  **    To  change how Amazon ML splits the data for a
                datasource, use the strategy parameter. The default value  for
                the  strategy parameter is sequential , meaning that Amazon ML
                takes all of the data records  between  the  percentBegin  and
                percentEnd  parameters  for  the datasource, in the order that
                the records appear  in  the  input  data.  The  following  two
                DataRearrangement  lines  are examples of sequentially ordered
                training and evaluation datasources:  Datasource  for  evalua-
                tion:    {"splitting":{"percentBegin":70,    "percentEnd":100,
                "strategy":"sequential"}}   Datasource for training:  {"split-
                ting":{"percentBegin":70,       "percentEnd":100,      "strat-
                egy":"sequential", "complement":"true"}}   To  randomly  split
                the  input data into the proportions indicated by the percent-
                Begin and percentEnd parameters, set the strategy parameter to
                random and provide a string that is used as the seed value for
                the random data splitting (for example, you  can  use  the  S3
                path  to  your  data as the random seed string). If you choose
                the random split strategy, Amazon ML assigns each row of  data
                a pseudo-random number between 0 and 100, and then selects the
                rows that have an assigned  number  between  percentBegin  and
                percentEnd . Pseudo-random numbers are assigned using both the
                input seed string value and the byte  offset  as  a  seed,  so
                changing  the  data results in a different split. Any existing
                ordering is preserved. The random splitting  strategy  ensures
                that  variables  in  the training and evaluation data are dis-
                tributed similarly. It is useful in the cases where the  input
                data  may  have  an implicit sort order, which would otherwise
                result  in  training  and  evaluation  datasources  containing
                non-similar  data records. The following two DataRearrangement
                lines are examples of non-sequentially  ordered  training  and
                evaluation  datasources:  Datasource  for evaluation: {"split-
                ting":{"percentBegin":70,  "percentEnd":100,  "strategy":"ran-
                dom", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}   Data-
                source for  training:  {"splitting":{"percentBegin":70,  "per-
                centEnd":100,           "strategy":"random",          "random-
                Seed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}

          DataSchema -> (string)
              A  JSON string that represents the schema for an Amazon Redshift
              DataSource . The DataSchema defines the structure of the  obser-
              vation data in the data file(s) referenced in the DataSource .

              A DataSchema is not required if you specify a DataSchemaUri .

              Define   your   DataSchema  as  a  series  of  key-value  pairs.
              attributes and excludedVariableNames have an array of  key-value
              pairs  for  their value. Use the following format to define your
              DataSchema .

              { "version": "1.0",

              "recordAnnotationFieldName": "F1",

              "recordWeightFieldName": "F2",

              "targetFieldName": "F3",

              "dataFormat": "CSV",

              "dataFileContainsHeader": true,

              "attributes": [

              { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2",
              "fieldType":  "NUMERIC"  },  {  "fieldName":  "F3", "fieldType":
              "CATEGORICAL" }, { "fieldName": "F4", "fieldType": "NUMERIC"  },
              {  "fieldName":  "F5",  "fieldType":  "CATEGORICAL" }, { "field-
              Name": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "field-
              Type":  "WEIGHTED_INT_SEQUENCE"  }, { "fieldName": "F8", "field-
              Type": "WEIGHTED_STRING_SEQUENCE" } ],

              "excludedVariableNames": [ "F6" ] }

          DataSchemaUri -> (string)
              Describes the schema location for an Amazon Redshift  DataSource
              .

       Shorthand Syntax:

          DatabaseInformation={DatabaseName=string,ClusterIdentifier=string},SelectSqlQuery=string,DatabaseCredentials={Username=string,Password=string},S3StagingLocation=string,DataRearrangement=string,DataSchema=string,DataSchemaUri=string

       JSON Syntax:

          {
            "DatabaseInformation": {
              "DatabaseName": "string",
              "ClusterIdentifier": "string"
            },
            "SelectSqlQuery": "string",
            "DatabaseCredentials": {
              "Username": "string",
              "Password": "string"
            },
            "S3StagingLocation": "string",
            "DataRearrangement": "string",
            "DataSchema": "string",
            "DataSchemaUri": "string"
          }

       --role-arn (string)
          A fully specified role Amazon Resource Name (ARN). Amazon ML assumes
          the role on behalf of the user to create the following:

          o A security group to allow Amazon ML to execute the  SelectSqlQuery
            query on an Amazon Redshift cluster

          o An  Amazon  S3 bucket policy to grant Amazon ML read/write permis-
            sions on the S3StagingLocation

       --compute-statistics | --no-compute-statistics (boolean)
          The compute statistics for a DataSource . The statistics are  gener-
          ated  from  the observation data referenced by a DataSource . Amazon
          ML uses the statistics  internally  during  MLModel  training.  This
          parameter must be set to true if the DataSource needs to be used for
          MLModel training.

       --cli-input-json | --cli-input-yaml (string) Reads arguments  from  the
       JSON  string  provided.  The JSON string follows the format provided by
       --generate-cli-skeleton. If other arguments are provided on the command
       line,  those  values  will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the  string  will  be  taken literally. This may not be specified along
       with --cli-input-yaml.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample input YAML that can be used with --cli-input-yaml.  If  provided
       with  the  value  output, it validates the command inputs and returns a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       DataSourceId -> (string)
          A user-supplied ID that uniquely  identifies  the  datasource.  This
          value  should  be  identical to the value of the DataSourceID in the
          request.



                                            CREATE-DATA-SOURCE-FROM-REDSHIFT()

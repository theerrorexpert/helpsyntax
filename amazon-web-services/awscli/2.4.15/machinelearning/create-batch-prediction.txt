CREATE-BATCH-PREDICTION()                            CREATE-BATCH-PREDICTION()



NAME
       create-batch-prediction -

DESCRIPTION
       Generates  predictions for a group of observations. The observations to
       process exist in one or more data files referenced by  a  DataSource  .
       This  operation creates a new BatchPrediction , and uses an MLModel and
       the data files referenced by the DataSource as information sources.
          CreateBatchPrediction is an asynchronous operation. In  response  to
          CreateBatchPrediction  , Amazon Machine Learning (Amazon ML) immedi-
          ately returns and sets the BatchPrediction status to PENDING . After
          the  BatchPrediction  completes,  Amazon  ML sets the status to COM-
          PLETED .

       You can poll for status updates by using the  GetBatchPrediction opera-
       tion  and  checking  the Status parameter of the result. After the COM-
       PLETED status appears, the results are available in the location speci-
       fied by the OutputUri parameter.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-batch-prediction
          --batch-prediction-id <value>
          [--batch-prediction-name <value>]
          --ml-model-id <value>
          --batch-prediction-data-source-id <value>
          --output-uri <value>
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --batch-prediction-id (string)
          A user-supplied ID that uniquely identifies the BatchPrediction .

       --batch-prediction-name (string)
          A  user-supplied name or description of the BatchPrediction . Batch-
          PredictionName can only use the UTF-8 character set.

       --ml-model-id (string)
          The ID of the MLModel that will generate predictions for  the  group
          of observations.

       --batch-prediction-data-source-id (string)
          The ID of the DataSource that points to the group of observations to
          predict.

       --output-uri (string)
          The location of an Amazon Simple Storage Service (Amazon S3)  bucket
          or  directory  to  store the batch prediction results. The following
          substrings are not allowed in the s3 key portion  of  the  outputURI
          field: ':', '//', '/./', '/../'.

          Amazon  ML  needs permissions to store and retrieve the logs on your
          behalf. For information about how to set permissions, see the Amazon
          Machine Learning Developer Guide .

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       BatchPredictionId -> (string)
          A  user-supplied  ID  that uniquely identifies the BatchPrediction .
          This value is identical to the value of the BatchPredictionId in the
          request.



                                                     CREATE-BATCH-PREDICTION()

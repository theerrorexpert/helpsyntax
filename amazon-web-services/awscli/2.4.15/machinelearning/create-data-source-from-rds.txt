CREATE-DATA-SOURCE-FROM-RDS()                    CREATE-DATA-SOURCE-FROM-RDS()



NAME
       create-data-source-from-rds -

DESCRIPTION
       Creates  a DataSource object from an Amazon Relational Database Service
       (Amazon RDS). A DataSource references data that can be used to  perform
       CreateMLModel , CreateEvaluation , or CreateBatchPrediction operations.
          CreateDataSourceFromRDS is an asynchronous operation. In response to
          CreateDataSourceFromRDS  , Amazon Machine Learning (Amazon ML) imme-
          diately returns and sets the DataSource status to  PENDING  .  After
          the DataSource is created and ready for use, Amazon ML sets the Sta-
          tus parameter to COMPLETED . DataSource in the COMPLETED or  PENDING
          state can be used only to perform >CreateMLModel >, CreateEvaluation
          , or CreateBatchPrediction operations.

       If Amazon ML cannot accept the input source, it sets the Status parame-
       ter to FAILED and includes an error message in the Message attribute of
       the GetDataSource operation response.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            create-data-source-from-rds
          --data-source-id <value>
          [--data-source-name <value>]
          --rds-data <value>
          --role-arn <value>
          [--compute-statistics | --no-compute-statistics]
          [--cli-input-json | --cli-input-yaml]
          [--generate-cli-skeleton <value>]

OPTIONS
       --data-source-id (string)
          A user-supplied ID that uniquely identifies the DataSource  .  Typi-
          cally,  an  Amazon  Resource Number (ARN) becomes the ID for a Data-
          Source .

       --data-source-name (string)
          A user-supplied name or description of the DataSource .

       --rds-data (structure)
          The data specification of an Amazon RDS DataSource :

          o DatabaseInformation -

            o DatabaseName - The name of the Amazon RDS database.

            o InstanceIdentifier - A unique  identifier  for  the  Amazon  RDS
              database instance.

          o DatabaseCredentials  -  AWS  Identity  and Access Management (IAM)
            credentials that are used to connect to the Amazon RDS database.

          o ResourceRole - A role (DataPipelineDefaultResourceRole) assumed by
            an EC2 instance to carry out the copy task from Amazon RDS to Ama-
            zon Simple Storage Service (Amazon S3). For more information,  see
            Role templates for data pipelines.

          o ServiceRole  - A role (DataPipelineDefaultRole) assumed by the AWS
            Data Pipeline service to monitor the progress  of  the  copy  task
            from  Amazon RDS to Amazon S3. For more information, see Role tem-
            plates for data pipelines.

          o SecurityInfo - The security information to use to access an RDS DB
            instance.  You  need  to  set up appropriate ingress rules for the
            security entity IDs provided to allow access  to  the  Amazon  RDS
            instance.  Specify  a  [SubnetId  ,  SecurityGroupIds ] pair for a
            VPC-based RDS DB instance.

          o SelectSqlQuery - A query that is used to retrieve the  observation
            data for the Datasource .

          o S3StagingLocation  - The Amazon S3 location for staging Amazon RDS
            data. The data retrieved from Amazon RDS using  SelectSqlQuery  is
            stored in this location.

          o DataSchemaUri - The Amazon S3 location of the DataSchema .

          o DataSchema  -  A  JSON string representing the schema. This is not
            required if DataSchemaUri is specified.

          o DataRearrangement - A JSON string that  represents  the  splitting
            and  rearrangement  requirements  for  the  Datasource .  Sample -
            "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"

          DatabaseInformation -> (structure)
              Describes the DatabaseName and InstanceIdentifier of  an  Amazon
              RDS database.

              InstanceIdentifier -> (string)
                 The ID of an RDS DB instance.

              DatabaseName -> (string)
                 The name of a database hosted on an RDS DB instance.

          SelectSqlQuery -> (string)
              The  query that is used to retrieve the observation data for the
              DataSource .

          DatabaseCredentials -> (structure)
              The AWS Identity and Access Management  (IAM)  credentials  that
              are used connect to the Amazon RDS database.

              Username -> (string)
                 The  username  to be used by Amazon ML to connect to database
                 on an Amazon RDS instance. The username  should  have  suffi-
                 cient permissions to execute an RDSSelectSqlQuery query.

              Password -> (string)
                 The password to be used by Amazon ML to connect to a database
                 on an RDS DB instance. The password  should  have  sufficient
                 permissions to execute the RDSSelectQuery query.

          S3StagingLocation -> (string)
              The  Amazon  S3  location  for staging Amazon RDS data. The data
              retrieved from Amazon RDS using SelectSqlQuery is stored in this
              location.

          DataRearrangement -> (string)
              A  JSON  string  that represents the splitting and rearrangement
              processing to be applied to a DataSource . If the DataRearrange-
              ment parameter is not provided, all of the input data is used to
              create the Datasource .

              There are multiple parameters that control what data is used  to
              create a datasource:

              o
                **
                percentBegin  **    Use percentBegin to indicate the beginning
                of the range of the data used to create the Datasource. If you
                do  not  include  percentBegin  and  percentEnd  ,  Amazon  ML
                includes all of the data when creating the datasource.

              o
                **
                percentEnd **   Use percentEnd to  indicate  the  end  of  the
                range of the data used to create the Datasource. If you do not
                include percentBegin and percentEnd , Amazon ML  includes  all
                of the data when creating the datasource.

              o
                **
                complement  **    The complement parameter instructs Amazon ML
                to use the data that is not included in the range of  percent-
                Begin  to  percentEnd  to  create a datasource. The complement
                parameter is useful if you need to create complementary  data-
                sources for training and evaluation. To create a complementary
                datasource, use the same  values  for  percentBegin  and  per-
                centEnd  ,  along  with the complement parameter. For example,
                the following two datasources do not share any data,  and  can
                be  used  to  train and evaluate a model. The first datasource
                has 25 percent of the data, and the second one has 75  percent
                of  the  data.  Datasource for evaluation: {"splitting":{"per-
                centBegin":0,  "percentEnd":25}}    Datasource  for  training:
                {"splitting":{"percentBegin":0,    "percentEnd":25,   "comple-
                ment":"true"}}

              o
                **
                strategy **   To change how Amazon ML splits the  data  for  a
                datasource,  use the strategy parameter. The default value for
                the strategy parameter is sequential , meaning that Amazon  ML
                takes  all  of  the  data records between the percentBegin and
                percentEnd parameters for the datasource, in  the  order  that
                the  records  appear  in  the  input  data.  The following two
                DataRearrangement lines are examples of  sequentially  ordered
                training  and  evaluation  datasources: Datasource for evalua-
                tion:    {"splitting":{"percentBegin":70,    "percentEnd":100,
                "strategy":"sequential"}}    Datasource for training: {"split-
                ting":{"percentBegin":70,      "percentEnd":100,       "strat-
                egy":"sequential",  "complement":"true"}}    To randomly split
                the input data into the proportions indicated by the  percent-
                Begin and percentEnd parameters, set the strategy parameter to
                random and provide a string that is used as the seed value for
                the  random  data  splitting  (for example, you can use the S3
                path to your data as the random seed string).  If  you  choose
                the  random split strategy, Amazon ML assigns each row of data
                a pseudo-random number between 0 and 100, and then selects the
                rows  that  have  an  assigned number between percentBegin and
                percentEnd . Pseudo-random numbers are assigned using both the
                input  seed  string  value  and  the byte offset as a seed, so
                changing the data results in a different split.  Any  existing
                ordering  is  preserved. The random splitting strategy ensures
                that variables in the training and evaluation  data  are  dis-
                tributed  similarly. It is useful in the cases where the input
                data may have an implicit sort order,  which  would  otherwise
                result  in  training  and  evaluation  datasources  containing
                non-similar data records. The following two  DataRearrangement
                lines  are  examples  of non-sequentially ordered training and
                evaluation datasources: Datasource  for  evaluation:  {"split-
                ting":{"percentBegin":70,  "percentEnd":100,  "strategy":"ran-
                dom", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}   Data-
                source  for  training:  {"splitting":{"percentBegin":70, "per-
                centEnd":100,          "strategy":"random",           "random-
                Seed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}

          DataSchema -> (string)
              A JSON string that represents the schema for an Amazon RDS Data-
              Source . The DataSchema defines the structure of the observation
              data in the data file(s) referenced in the DataSource .

              A DataSchema is not required if you specify a DataSchemaUri

              Define  your  DataSchema  as  a  series  of   key-value   pairs.
              attributes  and excludedVariableNames have an array of key-value
              pairs for their value. Use the following format to  define  your
              DataSchema .

              { "version": "1.0",

              "recordAnnotationFieldName": "F1",

              "recordWeightFieldName": "F2",

              "targetFieldName": "F3",

              "dataFormat": "CSV",

              "dataFileContainsHeader": true,

              "attributes": [

              { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2",
              "fieldType": "NUMERIC"  },  {  "fieldName":  "F3",  "fieldType":
              "CATEGORICAL"  }, { "fieldName": "F4", "fieldType": "NUMERIC" },
              { "fieldName": "F5", "fieldType":  "CATEGORICAL"  },  {  "field-
              Name": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "field-
              Type": "WEIGHTED_INT_SEQUENCE" }, { "fieldName":  "F8",  "field-
              Type": "WEIGHTED_STRING_SEQUENCE" } ],

              "excludedVariableNames": [ "F6" ] }

          DataSchemaUri -> (string)
              The Amazon S3 location of the DataSchema .

          ResourceRole -> (string)
              The  role (DataPipelineDefaultResourceRole) assumed by an Amazon
              Elastic Compute Cloud (Amazon EC2) instance  to  carry  out  the
              copy  operation  from  Amazon RDS to an Amazon S3 task. For more
              information, see Role templates for data pipelines.

          ServiceRole -> (string)
              The role (DataPipelineDefaultRole) assumed by AWS Data  Pipeline
              service to monitor the progress of the copy task from Amazon RDS
              to Amazon S3. For more information, see Role templates for  data
              pipelines.

          SubnetId -> (string)
              The  subnet ID to be used to access a VPC-based RDS DB instance.
              This attribute is used by Data Pipeline to carry  out  the  copy
              task from Amazon RDS to Amazon S3.

          SecurityGroupIds -> (list)
              The  security  group IDs to be used to access a VPC-based RDS DB
              instance. Ensure that there are appropriate ingress rules set up
              to  allow  access to the RDS DB instance. This attribute is used
              by Data Pipeline to carry out the copy operation from Amazon RDS
              to an Amazon S3 task.

              (string)

       Shorthand Syntax:

          DatabaseInformation={InstanceIdentifier=string,DatabaseName=string},SelectSqlQuery=string,DatabaseCredentials={Username=string,Password=string},S3StagingLocation=string,DataRearrangement=string,DataSchema=string,DataSchemaUri=string,ResourceRole=string,ServiceRole=string,SubnetId=string,SecurityGroupIds=string,string

       JSON Syntax:

          {
            "DatabaseInformation": {
              "InstanceIdentifier": "string",
              "DatabaseName": "string"
            },
            "SelectSqlQuery": "string",
            "DatabaseCredentials": {
              "Username": "string",
              "Password": "string"
            },
            "S3StagingLocation": "string",
            "DataRearrangement": "string",
            "DataSchema": "string",
            "DataSchemaUri": "string",
            "ResourceRole": "string",
            "ServiceRole": "string",
            "SubnetId": "string",
            "SecurityGroupIds": ["string", ...]
          }

       --role-arn (string)
          The  role that Amazon ML assumes on behalf of the user to create and
          activate a data pipeline in the user's account and copy  data  using
          the SelectSqlQuery query from Amazon RDS to Amazon S3.

       --compute-statistics | --no-compute-statistics (boolean)
          The  compute statistics for a DataSource . The statistics are gener-
          ated from the observation data referenced by a DataSource  .  Amazon
          ML  uses  the  statistics  internally  during MLModel training. This
          parameter must be set to true if the DataSourceneeds to be used  for
          MLModel training.

       --cli-input-json  |  --cli-input-yaml (string) Reads arguments from the
       JSON string provided. The JSON string follows the  format  provided  by
       --generate-cli-skeleton. If other arguments are provided on the command
       line, those values will override the JSON-provided values.  It  is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally. This may  not  be  specified  along
       with --cli-input-yaml.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. Similarly, if provided yaml-input it will print a
       sample  input  YAML that can be used with --cli-input-yaml. If provided
       with the value output, it validates the command inputs  and  returns  a
       sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       DataSourceId -> (string)
          A  user-supplied  ID  that  uniquely identifies the datasource. This
          value should be identical to the value of the  DataSourceID  in  the
          request.



                                                 CREATE-DATA-SOURCE-FROM-RDS()
